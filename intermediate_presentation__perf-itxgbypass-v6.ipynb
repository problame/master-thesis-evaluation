{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_storage_prefix = \"itxg_bypass_v6\"\n",
    "\n",
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "    (\"zfs_setup.module_args.zfs.zfs_zil_itxg_bypass\", \"itxg_bypass\", str),\n",
    "    (\"zfs_setup.module_args.zfs.zvol_request_sync\", \"zvol_request_sync\", str), # technically not in the v6 set, but that's just because we limited the scope of the benchmark for time reasons\n",
    "    (\"zfs_setup.module_args.zfs.zfs_zil_pmem_prb_ncommitters\", \"ncommitters\", int),\n",
    "    (\"fio_config.fsync_every\", \"fsync_every\", int),\n",
    "    (\"fio_config.numjobs\", \"numjobs\", int)\n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return jw\n",
    "\n",
    "def to_fio_results_dict(output_json):\n",
    "    jw = get_fio_write_metrics(output_json)\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "    }\n",
    "\n",
    "def to_kstat_results_dict(output_json):\n",
    "    d = output_json\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        **d[\"zvol_stats\"],\n",
    "        **d[\"itxg_bypass_stats\"],\n",
    "        **d[\"zil_pmem_stats\"],\n",
    "        **d[\"zil_pmem_ringbuf_stats\"],\n",
    "        \"bio_total\": d[\"zvol_stats\"][\"submit_bio__zvol_write(with_taskq_if_enabled)\"],\n",
    "        \"taskq_delay\": dotted.get(d, 'zvol_stats.zvol_write__taskq_qdelay'),\n",
    "        \"assign_aquire\": dotted.get(d, 'itxg_bypass_stats.assign__aquisition_total'),\n",
    "        \"assign_vtable\": dotted.get(d, 'itxg_bypass_stats.assign__vtable'),\n",
    "        \"assign_total\": dotted.get(d, 'itxg_bypass_stats.assign__total'),\n",
    "        \"commit_total\": dotted.get(d, 'itxg_bypass_stats.commit__total'),\n",
    "        \"commit_aquire\": dotted.get(d, 'itxg_bypass_stats.commit__aquire'),\n",
    "        \n",
    "    }\n",
    "\n",
    "def to_cpu_dict(output_json):\n",
    "    d = output_json\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        **{f\"cpu_{comp}\": val for comp, val in dotted.get(d, \"cpu_time.allcpu\").items()},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute `df_kstats`\n",
    "rows = [to_kstat_results_dict(j) for j in result_storage.iter_results(result_storage_prefix)]\n",
    "df_kstats = pd.DataFrame.from_dict(rows).set_index(id_vars).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute `df_cpu`\n",
    "rows = [to_cpu_dict(j) for j in result_storage.iter_results(result_storage_prefix)]\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars).sort_index()\n",
    "df = df.rename_axis(\"metric\", axis=1)\n",
    "df = df.stack()\n",
    "df_cpu = df\n",
    "del df\n",
    "df_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## derive `df_cpu.notidle`\n",
    "tmp = df_cpu.unstack(\"metric\")\n",
    "tmp[\"cpu_not_idle\"] = tmp.sum(axis=1) - tmp.cpu_idle\n",
    "df_cpu = tmp.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute `df`\n",
    "rows = [to_fio_results_dict(j) for j in result_storage.iter_results(result_storage_prefix)]\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars).sort_index()\n",
    "df = df.rename_axis(\"metric\", axis=1)\n",
    "df = df.stack()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick peek on the actual data in `df`\n",
    "df.unstack(\"metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define df_zfssetup\n",
    "data = df.unstack([\"itxg_bypass\", \"zvol_request_sync\", \"ncommitters\"])\n",
    "data.columns = data.columns.map(lambda x: f\"zil-pmem bypass={x[0]} zvol_taskq={ {'1':'no', '0':'yes'}[x[1]] } ncommitters={x[2]}\")\n",
    "data = data.rename_axis(\"zfs_setup\", axis=1)\n",
    "data = data.stack()\n",
    "data\n",
    "df_zfssetup = data\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def filter_by_index_value(df, level, filter):\n",
    "    \"\"\"Return a new df that only contains rows whose MultiIndex column `level`'s value passes `filter`\"\"\"\n",
    "    return df[df.index.get_level_values(level).map(filter)]\n",
    "\n",
    "def remove_index_dimension(df, level, value):\n",
    "    \"\"\"Reduce dimensionality of a dataframe by filtering by and subsequently dropping one of its index levels.\n",
    "    \n",
    "    df is assumed to be a multi-indexed pd.DataFrame.\n",
    "    First, filter the data frame so that we only keep rows whose index tuple has value `value` at level `level`.\n",
    "    Now the resulting data frame only has a single value at the level.\n",
    "    Thus remove that level from the index.\n",
    "    Voila: dimensionality reduced.\n",
    "    \"\"\"\n",
    "    df = df[df.index.get_level_values(level) == value]\n",
    "    assert set(df.index.get_level_values(level)) == {value}\n",
    "    df.index = df.index.droplevel(level)\n",
    "    return df\n",
    "\n",
    "def _test_remove_index_dimension():\n",
    "    data = [{\"favnum\": n, \"favletter\": l, \"id\": id} for id, (n, l) in enumerate(itertools.product([23,42],[\"a\", \"b\"]))]\n",
    "    d = pd.DataFrame(data).set_index([\"favnum\", \"favletter\"])\n",
    "    display(d)\n",
    "    display(remove_index_dimension(d, \"favnum\", 23))\n",
    "    display(remove_index_dimension(d, \"favletter\", \"b\"))\n",
    "    \n",
    "_test_remove_index_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_values_sorted_unique(df, level):\n",
    "    \"\"\"Returns the sorted unique values of a DataFrame's multi-index at level `level`\"\"\"\n",
    "    return sorted(list(set(df.index.get_level_values(level))))\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "class FactorizedDataFrameItem(AttrDict):\n",
    "    @property\n",
    "    def title(self):\n",
    "        return f\"{self.fdf.row}={self.rv}|{self.fdf.col}={self.cv}\"\n",
    "        \n",
    "        \n",
    "class FactorizedDataFrame:\n",
    "    def __init__(self, data, row, col):\n",
    "        self.data = data\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "\n",
    "        self.col_values = level_values_sorted_unique(self.data, self.col)\n",
    "        self.row_values = level_values_sorted_unique(self.data, self.row)\n",
    "        \n",
    "    def iter_factorized(self):\n",
    "        for ci, c in enumerate(self.col_values):\n",
    "            for ri, r in enumerate(self.row_values):\n",
    "                d = self.data.copy()\n",
    "                d = remove_index_dimension(d, self.col, c)\n",
    "                d = remove_index_dimension(d, self.row, r)\n",
    "                # display(d)\n",
    "            \n",
    "                context = FactorizedDataFrameItem({\n",
    "                    \"fdf\": self,\n",
    "                    \"d\": d,\n",
    "                    \"ri\": ri,\n",
    "                    \"rv\": r,\n",
    "                    \"ci\": ci,\n",
    "                    \"cv\": c,\n",
    "                })\n",
    "                yield context\n",
    "                \n",
    "\n",
    "def factorplot(data=None, row=None, col=None, plot=None, subplots_kw={}):\n",
    "    \"\"\"Factorizez MultiIndex'ed DataFrame `data`, then invokes `plot` for each FactorizedDataFrameItem\"\"\"\n",
    "    \n",
    "    fdf = FactorizedDataFrame(data, row, col)\n",
    "    \n",
    "    subplots_kw = {\n",
    "        \"gridspec_kw\": {'hspace': 1},\n",
    "        **subplots_kw,\n",
    "        \"squeeze\": False, # axes should always be two-dimensional\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(len(fdf.row_values), len(fdf.col_values), **subplots_kw)\n",
    "\n",
    "    for f in fdf.iter_factorized():\n",
    "        ax = axes[f.ri, f.ci]\n",
    "        ax.set_title(f.title)\n",
    "        legend = f.ri == len(fdf.row_values)-1 and f.ci == len(fdf.col_values)-1\n",
    "        plot(f, ax, legend)\n",
    "        if legend:\n",
    "            plt.legend(loc='lower left', bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kstats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def compute_latency_components(normalize=None):\n",
    "\n",
    "    # compute latency breakdown variables\n",
    "    data = df_kstats.copy()\n",
    "    data['t_taskq'] = data.zvol_write__taskq_qdelay\n",
    "    data['t_bypass_commit'] = data.commit_total\n",
    "    data['t_bypass_assign_aquisition'] = data.assign__aquisition_total\n",
    "    data['t_bypass_assign_exit'] = data.assign__exit\n",
    "    data['prb_total'] = data.write_entry_time - data.prb_write__pmem\n",
    "    data['t_prb_sem'] = data.prb_write__get_committer_slot + data.prb_write__put_committer_slot\n",
    "    data['t_prb_dt_aq'] = data.prb_write__dt_sl_aquisition\n",
    "    data['t_prb_other'] = data.prb_total - (data.t_prb_sem + data.t_prb_dt_aq)\n",
    "    data['t_pmem'] = data.prb_write__pmem\n",
    "    data['t_get_data'] = data.get_data_time\n",
    "    data['t_zil'] = data.assign__vtable - data.write_entry_time\n",
    "    data['t_zvol_write'] = data.bio_total - (data.zvol_write__taskq_qdelay + data.zvol_write__1zil_commit + data.zvol_write__zvol_log_write_finish + data.zvol_write__2zil_commit)\n",
    "    \n",
    "    components = ['t_taskq', 't_bypass_commit', 't_bypass_assign_aquisition',\n",
    "                  't_bypass_assign_exit', 't_prb_sem', 't_prb_dt_aq', 't_prb_other', 't_pmem', 't_get_data', 't_zil', 't_zvol_write']\n",
    "    \n",
    "    # t_other is what we didn't account for yet\n",
    "    data['t_other'] = data.bio_total - data[components].sum(axis=1)\n",
    "    components += ['t_other']\n",
    "\n",
    "    data = normalize(data)\n",
    "\n",
    "    # project to components\n",
    "    data = data[components]\n",
    "\n",
    "\n",
    "    data = data.rename_axis('component', axis=1)\n",
    "    data = data.stack()\n",
    "    data.name = \"t\"\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "\n",
    "def normalize_by_numjobs(data):\n",
    "    tmp = data.reset_index(level='numjobs')\n",
    "    numjobs_orig = tmp.numjobs\n",
    "    tmp = tmp.div(tmp.numjobs, axis=0)\n",
    "    tmp['numjobs'] = numjobs_orig\n",
    "    tmp = tmp.set_index('numjobs', append=True)\n",
    "    return tmp\n",
    "\n",
    "def normalize_by_numjobs_except_t_pmem(data):\n",
    "    tmp = data.reset_index(level='numjobs')\n",
    "    numjobs_orig = tmp.numjobs\n",
    "    tmp = tmp.div(tmp.numjobs, axis=0)\n",
    "    tmp['t_pmem'] = tmp['t_pmem'].mul(numjobs_orig) # !!!!!!!!!!!! don't normalize t_pmem\n",
    "    tmp['numjobs'] = numjobs_orig\n",
    "    tmp = tmp.set_index('numjobs', append=True)\n",
    "    return tmp\n",
    "\n",
    "def normalize_by_bio_total(data):\n",
    "    return data.div(data.bio_total, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How The Latency Breakdown Evolves For Different `itxg_bypass` x `ncommitters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_var = 'itxg_bypass'\n",
    "row_var_values = [\"1\", \"2\"]\n",
    "col_var = 'ncommitters'\n",
    "col_var_values = [1,2,4,6,8,12,16,24]\n",
    "xlim=(0,16)\n",
    "xticks=range(0,17, 2)\n",
    "\n",
    "def filter_idvars(data):\n",
    "    data = remove_index_dimension(data, 'zvol_request_sync', \"1\")\n",
    "    data = remove_index_dimension(data, 'fsync_every', 32)\n",
    "    data = filter_by_index_value(data, col_var, lambda v: v in col_var_values)\n",
    "    data = filter_by_index_value(data, row_var, lambda v: v in row_var_values)\n",
    "#     data = data.query('@row_var in @row_var_values')\n",
    "    data = data.query('numjobs <= 16')\n",
    "#     data = data.query('ncommitters in [1,2,4,6,8,12,16,24] and fsync_every in [1,16,32] and numjobs <= 16')\n",
    "    return data\n",
    "\n",
    "def make_data(normalize=None):\n",
    "    data = compute_latency_components(normalize=normalize)    \n",
    "    return filter_idvars(data)\n",
    "\n",
    "print(\"relative latency breakdown\")\n",
    "\n",
    "def plot_rel_latency_breakdown(f, ax, legend):\n",
    "    f.d.plot.area(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=(-0.1, 1.1))\n",
    "\n",
    "data_lb = make_data(normalize=normalize_by_bio_total).unstack(\"component\")\n",
    "factorplot(data=data_lb, col=col_var, row=row_var, plot=plot_rel_latency_breakdown,\n",
    "          subplots_kw={\n",
    "            \"figsize\": (30, 10),\n",
    "            \"gridspec_kw\": {\n",
    "                \"hspace\": 0.2,\n",
    "            },\n",
    "        })\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print(\"absolute latency stacked\")\n",
    "\n",
    "# def plot_abs_latency_breakdown(f, ax, legend):\n",
    "#     f.d.plot.area(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=(0, 1.1*f.fdf.data.sum(axis=1).max()))\n",
    "# data_lb = make_data(normalize=lambda d: d).unstack(\"component\")\n",
    "# # display(data_lb.loc[(\"1\",1)])\n",
    "# factorplot(data=data_lb, col=col_var, row=row_var, plot=plot_abs_latency_breakdown,\n",
    "#           subplots_kw={\n",
    "#             \"figsize\": (30, 10),\n",
    "#             \"gridspec_kw\": {\n",
    "#                 \"hspace\": 0.2,\n",
    "#             },\n",
    "#         })\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "Absolute latencies divided by numjobs, EXCEPT t_pmem.\n",
    "\n",
    "Rationale: This section of the evaluation is about evaluating the PMEM write overhead limiter.\n",
    "Reminder: Writing to PMEM above its write bandwidth limit wastes CPU time because the write\n",
    "          instructions stall waiting for PMEM.\n",
    "This means that an ideal implementation would allow t_pmem to reach the value where we achieve\n",
    "peak performance (IOPS in our case), then keep the value at that level by queuing additional\n",
    "writers on the CPU (we do it using a semaphore in t_prb).\n",
    "Thus, an ideal t_pmem should look like so:\n",
    "\n",
    "   _____________\n",
    "  /\n",
    " /\n",
    "/\n",
    "\n",
    "If we divided t_pmem by `numjobs` like all the other `t_` metrics, that straight line would\n",
    "need to turn into a declining line, proportional to `numjobs`.\n",
    "That's quite hard to spot, so we felt it's better to not scale t_pmem at all.\n",
    "\"\"\")\n",
    "\n",
    "def plot_latency_curves(f, ax, legend):\n",
    "    f.d.plot.line(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=(0, 1.1*f.fdf.data.max().max()))\n",
    "data_abs = make_data(normalize=normalize_by_numjobs_except_t_pmem).unstack(\"component\")\n",
    "factorplot(data=data_abs, col=col_var, row=row_var, plot=plot_latency_curves,\n",
    "          subplots_kw={\n",
    "            \"figsize\": (30, 10),\n",
    "            \"gridspec_kw\": {\n",
    "                \"hspace\": 0.2,\n",
    "            },\n",
    "        })\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"performance metrics\")\n",
    "\n",
    "def plot_perf_metric(metric):\n",
    "\n",
    "    full_data = df.unstack(\"metric\")\n",
    "    full_data = filter_idvars(full_data)\n",
    "    full_data = full_data[[metric]]\n",
    "#     ymax = full_data[metric].max() * 1.1\n",
    "\n",
    "    def plot(f, ax, legend):\n",
    "    #     display(data)\n",
    "        #     data = data.pivot(\"numjobs\", \"metric\", \"value\")\n",
    "        #data.plot.line(ax=ax, legend=legend, xlim=(0, None), ylim=(0, context[\"full_data\"][metric].max()))\n",
    "        f.d.plot.line(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=(0, 1.1*f.fdf.data.max().max()))\n",
    "\n",
    "    factorplot(data=full_data, col=col_var, row=row_var,\n",
    "              plot=plot,\n",
    "              subplots_kw={\n",
    "                \"figsize\": (30, 5),\n",
    "                \"gridspec_kw\": {\n",
    "                    \"hspace\": 1,\n",
    "                }\n",
    "              })\n",
    "    plt.show()\n",
    "\n",
    "print(\"IOPS mean\")\n",
    "plot_perf_metric(\"w_iops_mean\")\n",
    "print(\"IOPS std\")\n",
    "plot_perf_metric(\"w_iops_stddev\")\n",
    "\n",
    "print(\"t_pmem / IOPS (how much time we spend writing PMEM per IOP (shouldn't grow after peak performance)\")\n",
    "t_pmem = make_data(normalize=lambda d: d).unstack(\"component\")[(\"t\", \"t_pmem\")]\n",
    "iops = df.unstack(\"metric\")[\"w_iops_mean\"]\n",
    "data = t_pmem / iops\n",
    "data.name = \"t_pmem/IOPS\"\n",
    "data = pd.DataFrame(data)\n",
    "data = filter_idvars(data)\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "#     display(data)\n",
    "    #     data = data.pivot(\"numjobs\", \"metric\", \"value\")\n",
    "    #data.plot.line(ax=ax, legend=legend, xlim=(0, None), ylim=(0, context[\"full_data\"][metric].max()))\n",
    "    f.d.plot.line(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=(0, 1*f.fdf.data.max().max()))\n",
    "\n",
    "factorplot(data=data, col=col_var, row=row_var,\n",
    "          plot=plot,\n",
    "          subplots_kw={\n",
    "            \"figsize\": (30, 5),\n",
    "            \"gridspec_kw\": {\n",
    "                \"hspace\": 1,\n",
    "            }\n",
    "          })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Some Latency Components are affected by different `itxg_bypass`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_var = 'ncommitters'\n",
    "col_var_values = [1,2,3,4,8]\n",
    "row_var = 'variable'\n",
    "row_var_values = [\"w_iops_mean\", \"t_pmem\", \"t_prb_sem\", \"t_bypass_assign_aquisition\", \"t_zvol_write\"]\n",
    "xlim=(0,16)\n",
    "xticks=range(0,17, 2)\n",
    "\n",
    "def filter_idvars(data):\n",
    "    data = remove_index_dimension(data, 'zvol_request_sync', \"1\")\n",
    "    data = remove_index_dimension(data, 'fsync_every', 32)\n",
    "    data = filter_by_index_value(data, col_var, lambda v: v in col_var_values)\n",
    "    data = filter_by_index_value(data, row_var, lambda v: v in row_var_values)\n",
    "#     data = data.query('@row_var in @row_var_values')\n",
    "    data = data.query('numjobs <= 16')\n",
    "#     data = data.query('ncommitters in [1,2,4,6,8,12,16,24] and fsync_every in [1,16,32] and numjobs <= 16')\n",
    "    return data\n",
    "\n",
    "def make_data(normalize=None):\n",
    "    data = compute_latency_components(normalize=normalize)    \n",
    "    data.index.rename('variable', 'component', inplace=True)\n",
    "    data.columns = ['value']\n",
    "    data['kind'] = 'latency_breakdown'\n",
    "    data['value'] = data.value / 1e9 # scale to seconds\n",
    "#     display(data)\n",
    "    \n",
    "#     data.columns.set_levels(['variable'], columns = data.rename_axis('variable')\n",
    "    perf = df.copy()\n",
    "    perf.index.rename(\"variable\", 'metric', inplace=True)\n",
    "    perf.name = 'value'\n",
    "    perf = pd.DataFrame(perf)\n",
    "    perf['kind'] = 'perf'\n",
    "#     display(perf)\n",
    "\n",
    "    data = pd.concat([data, perf], axis=0)\n",
    "#     display(data)\n",
    "    return filter_idvars(data)\n",
    "\n",
    "\n",
    "def plot_rel_latency_breakdown(f, ax, legend):\n",
    "    # this realizes 'sharey=False' \n",
    "    if f.rv == \"w_iops_mean\":\n",
    "        ymax = f.fdf.data[(f.fdf.data.kind == 'perf') & (f.fdf.data.index.get_level_values('variable') == f.rv)]['value'].max()\n",
    "    else:\n",
    "        ymax = f.fdf.data[(f.fdf.data.kind == 'latency_breakdown') & (f.fdf.data.index.get_level_values('variable') == f.rv)]['value'].max()\n",
    "    ylim=(0, 1.1*ymax)\n",
    "    f.d['value'].unstack(\"itxg_bypass\").plot.line(ax=ax, legend=legend, xlim=xlim, xticks=xticks, ylim=ylim)\n",
    "\n",
    "data_lb = make_data(normalize=lambda d: d)\n",
    "factorplot(data=data_lb, col=col_var, row=row_var, plot=plot_rel_latency_breakdown,\n",
    "          subplots_kw={\n",
    "            \"figsize\": (60, 20),\n",
    "            \"gridspec_kw\": {\n",
    "                \"hspace\": 0.5,\n",
    "            },\n",
    "        })\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reaffirms our observations in the previous section:\n",
    "- `itxg_bypass=1` spends most of its time in `itxg_bypass_assign_aquisition` (the rwlock) for `numjobs >= 6`\n",
    "  - The rwlock is used to add a serialization point on zil_commit(), which is required for correctness.\n",
    "    (A more scalable technique than rwlock might exist but that's out of scope for now)\n",
    "- `itxg_bypass=2` does not use the rwlock\n",
    "  - Thus it's incorrect from a ZIL perspective.\n",
    "  - But allows us to stress the PMEM Overload Protection functionality and observe how it scales.\n",
    "- => Comparison\n",
    "  - `ncommitters=1`:\n",
    "    - This `ncommitters` value does not achieve peak performance\n",
    "  - `ncommitters=2`:\n",
    "    - This `ncommitters` value achieves peak performance at `numjobs=6`\n",
    "    - `itxg_bypass=1` has a significant decline in peak performance for `numjobs > 9`\n",
    "    - `itxg_bypass=2` also shows a decline, but less so.\n",
    "    - (Keep in mind that we only have 8 cores (16 SMT threads))\n",
    "  - For `ncommitters>=3` we observe that IOPS do not improve beyond what we observed for `ncommitters=3`\n",
    "  - But the stability of the achieved IOPS over rising `numjobs` is different among the two `itxg_bypass` variants\n",
    "    - `itxg_bypass=1` IOPS stabilizes, albeit at the cost of wasting time on PMEM\n",
    "    - `itxg_bypass=2` IOPS drop at `(ncommitters,numjobs) = [(3,11),(4,13)]`.\n",
    "      - That drop in IOPS is explained by the combined cost of rwlock aquisition and prb semaphore aquisition time\n",
    "        - \"proof\": the drop goes away for `ncommitters=8`\n",
    "\n",
    "Conclusion:\n",
    "- PMEM overload protection works as intended: `t_pmem` does not rise after peak performance is reached if `ncommitters` is configured correctly (`1` or `2` for this setup)\n",
    "- `itxg_bypass=1` has the rwlock overhead which is significant even if ony `fsync_every=32`'th operation is serializing. That overhead relieves shifts wait time from `t_prb_rwsem` to `t_bypass_assign_aq`.\n",
    "\n",
    "Critique:\n",
    "- `itxg_bypass=2`'s drop in IOPS at `ncommitters=2` for `numjobs > 6` is suboptimal. Explanations?\n",
    "  - ???\n",
    "  - Maybe the optimal value is `ncommitters=2.X`?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
