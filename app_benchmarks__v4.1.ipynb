{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changlog:\n",
    "* v3.1:  Like v3 but with the ncommitters=4 results\n",
    "* v3.2:\n",
    "  * plus ZFSSyncDisabled\n",
    "  * several features for `compare_benchmarks`\n",
    "  * restructured grouping for better narative in evaluation\n",
    "* v3.3:\n",
    "  * benchmark runtimes tables to support claims in thesis\n",
    "  * prettier legend rendering\n",
    "* v4\n",
    "  * same dataset as v3 but with dm-writecache high-watermark=1\n",
    "    * low and high watermark = 0 maps all IO to NVMe, we don't want that\n",
    "    * with high wartermark = 1 (that is 1%), and our partition sizes, we get a nice constant background write-back to the NVMe that, according to iostat, doesn't push it to is limit (tops at 90% utilization @ 8 numjobs in fio)\n",
    "    * dm-writecache's lock contention is the bottleneck\n",
    "  * additional data filtering / exploration, didn't really lead anywhere\n",
    "* v4.1\n",
    "  * prettier graphs / prep for thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage\n",
    "from lib.helpers import merge_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "savefig_enable = True\n",
    "seaborn_context = \"paper\"\n",
    "savefig_dir = \"./postprocess_results\"\n",
    "textwidth = 5.5 #inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": seaborn_context,\n",
    "    \"savefig\": {\n",
    "        \"enable\": savefig_enable,\n",
    "        \"dir\": Path(savefig_dir),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_storage_prefix = \"app_benchmarks__v4\"\n",
    "\n",
    "def to_row(d):\n",
    "    \n",
    "    if dotted.get(d, 'result.exception') is True:\n",
    "        #print(f\"skipping benchmark that threw exception: {d}\")\n",
    "        return None\n",
    "    \n",
    "    if dotted.get(d, 'result.dummy') is not None:\n",
    "        return None # skip dummy\n",
    "    \n",
    "  \n",
    "    \n",
    "    blockdev_stack = dotted.get(d, 'storage_stack.blockdev_stack.identity')\n",
    "    if blockdev_stack is None:\n",
    "        blockdev_stack = 'native'\n",
    "    \n",
    "    storage_stack = dotted.get(d, 'storage_stack.fstyp')\n",
    "    if storage_stack is not None:\n",
    "        fstyp = storage_stack\n",
    "        storage_stack += \"__on__\" + blockdev_stack\n",
    "        storage_stack += \"__dax_\" + str(dotted.get(d, 'storage_stack.mount_dax'))\n",
    "        daxmount = dotted.get(d, 'storage_stack.mount_dax')\n",
    "    else:\n",
    "        storage_stack = dotted.get(d, 'storage_stack.identity')\n",
    "        m = re.match(r\"(?P<fstyp>zfs-(pmem|lwb|sync_disabled))-\", storage_stack)\n",
    "        assert m\n",
    "        fstyp = m['fstyp']\n",
    "        daxmount = None\n",
    "    assert storage_stack is not None\n",
    "    \n",
    "    benchmark_identity = dotted.get(d, 'result.identity')\n",
    "    \n",
    "    # fixup mariadb-sysbench-oltp_insert\n",
    "    if benchmark_identity == \"mariadb-sysbench-oltp_insert\":\n",
    "        m = d['result']['result']['metrics']\n",
    "        m['SQL_statistics'] = m['SQL statistics']\n",
    "        del m\n",
    "    \n",
    "    # determine variable_dotted_str and metric_dotted_strs\n",
    "    try:\n",
    "        variable_dotted_str, metric_dotted_strs = {\n",
    "            \"filebench-varmail\": ('result.config.vars.nthreads', ['result.result.metrics.summary_ops_per_sec']),\n",
    "            \"filebench-oltp\": ('result.config.vars.ndbwriters', ['result.result.metrics.summary_ops_per_sec']),\n",
    "            \"redis-SET\": ('result.config.clients', ['result.result.main.metrics.rps']),\n",
    "            \"rocksdb-fillsync\": ('result.config.threads', ['result.result.metrics.fillsync.ops_per_sec']),\n",
    "            \"sqlite-bench\": (None, ['result.result.metrics.fillrandsync.micros_per_op']),\n",
    "            \"mariadb-sysbench-oltp_insert\": ('result.config.threads', ['result.result.metrics.SQL_statistics.transactions_per_sec']),\n",
    "            \"fio-4k-sync-rand-write--size-per-job\": ('result.fio_config.numjobs', ['result.fio_jsonplus.jobs[0].write.iops']),\n",
    "            \"fio-4k-sync-rand-write--size-div-by-numjobs\": ('result.fio_config.numjobs', ['result.fio_jsonplus.jobs[0].write.iops']),\n",
    "        }[benchmark_identity]\n",
    "    except KeyError:\n",
    "        raise Exception(f\"unknown_benchmark {benchmark_identity}:\\n{d!r}\")\n",
    "    \n",
    "    # determine variable_value\n",
    "    if variable_dotted_str:\n",
    "        variable_value = dotted.get(d, variable_dotted_str)\n",
    "        if variable_value is None:\n",
    "            print(benchmark_identity)\n",
    "            raise Exception(str(d))\n",
    "    else:\n",
    "        variable_value = None\n",
    "        \n",
    "    # determine metric_value\n",
    "    if not metric_dotted_strs:\n",
    "        raise Exception(str(d))\n",
    "    metrics = {}\n",
    "    for mds in metric_dotted_strs:\n",
    "        mv = dotted.get(d, mds)\n",
    "        if not mv:\n",
    "            raise Exception(f\"mds: {mds}\\n{d!r}\")\n",
    "        if len(metrics) == 0:\n",
    "            metrics['primary_metric'] = mds\n",
    "            metrics['primary_metric_value'] = mv\n",
    "        metrics[mds] = mv \n",
    "        \n",
    "    bm_runtime_dotted_str = {\n",
    "        \"redis-SET\": 'result.result.main.runtime_secs',\n",
    "        \"rocksdb-fillsync\": 'result.result.runtime',\n",
    "    }.get(benchmark_identity, None)\n",
    "    if bm_runtime_dotted_str is not None:\n",
    "        bm_runtime = dotted.get(d, bm_runtime_dotted_str)\n",
    "        assert bm_runtime is not None\n",
    "    else:\n",
    "        bm_runtime = None\n",
    "    \n",
    "    return {\n",
    "        \"filepath\": d['file'],\n",
    "        \"storage_stack\": storage_stack,\n",
    "        \"blockdev_stack\": blockdev_stack,\n",
    "        \"daxmount\": daxmount,\n",
    "        \"fstyp\": fstyp,\n",
    "        \"benchmark\": benchmark_identity,\n",
    "        \"variable\": variable_dotted_str,\n",
    "        \"variable_value\": variable_value,\n",
    "        \"actual_runtime\": bm_runtime,\n",
    "        **metrics,\n",
    "    }\n",
    "\n",
    "def try_to_row(d):\n",
    "    try:\n",
    "        return to_row(d)\n",
    "    except:\n",
    "        print(d)\n",
    "        raise\n",
    "\n",
    "rows = [try_to_row(j) for j in result_storage.iter_results(result_storage_prefix)]\n",
    "rows = list(filter(lambda d: d is not None, rows))\n",
    "rows = list(itertools.chain(rows))\n",
    "df = pd.DataFrame(rows)\n",
    "df\n",
    "\n",
    "# df = df[df.blockdev_stack.map(lambda bd: \"writecache\" not in bd)]\n",
    "# for l in list(df.filepath.map(lambda r: f'cp {r} {r.replace(\"app_benchmarks__v3\", \"app_benchmarks__v4\")}')):\n",
    "#     print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['benchmark'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['storage_stack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['blockdev_stack'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df.copy().query('variable_value in [1, @nan] and benchmark in [\"redis-SET\", \"filebench-varmail\"]')\n",
    "nan = np.nan\n",
    "data = df.copy().query('variable_value in [1, @nan]')\n",
    "# data = df.copy().query('variable_value in [1, @nan] and benchmark in [\"redis-SET\", \"filebench-varmail\", \"rocksdb-fillsync\"]')\n",
    "# display(data)\n",
    "data = data.set_index(['benchmark', 'storage_stack', 'variable_value'], verify_integrity=True).sort_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Redis And RocksDB Runtimes Are Acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all runs that took < 10 seconds\n",
    "df[df.actual_runtime.map(lambda rt: rt is not None and rt < 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the only critical candidate is `zfs-pmem-rs_0-byp_0-nc_3` in rocksdb-fillsync.\n",
    "And zfs-sync-disabed.\n",
    "We address that in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.benchmark == 'redis-SET'].groupby('variable_value').actual_runtime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.benchmark == 'rocksdb-fillsync'].groupby('variable_value').actual_runtime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.benchmark == 'rocksdb-fillsync'].actual_runtime.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.benchmark == 'rocksdb-fillsync'].actual_runtime.quantile(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_metadata = {\n",
    "        \"filebench-oltp\": (\"fb-oltp\", 1/1_000, r'ops/s $\\times 10^3$'),\n",
    "        \"filebench-varmail\": (\"fb-varmail\", 1/1_000, r'ops/s $\\times 10^3$'),\n",
    "        'fio-4k-sync-rand-write--size-div-by-numjobs': ('fio-fixed', 1/1_000, r'IOPS $\\times 10^3$'),\n",
    "         'fio-4k-sync-rand-write--size-per-job': ('fio-growing', 1/1_000, r'IOPS $\\times 10^3$'),\n",
    "        'mariadb-sysbench-oltp_insert': ('MariaDB',1/1_000,  r'txn/s $\\times 10^3$'),\n",
    "        'rocksdb-fillsync': ('RocksDB',1/1_000, r'ops/s $\\times 10^3$'),  \n",
    "        'redis-SET': ('Redis-SET',1/1_000,  r'req/s $\\times 10^3$'),\n",
    "    }\n",
    "def rename_benchmark(benchmark):\n",
    "    return benchmark_metadata[benchmark][0]\n",
    "def benchmark_scale_value(benchmark, v):\n",
    "    return v * benchmark_metadata[benchmark][1]\n",
    "def benchmark_unit(benchmark):\n",
    "    return benchmark_metadata[benchmark][2]\n",
    "import itertools\n",
    "import re\n",
    "def rename_storage_stack(ss):\n",
    "    \n",
    "    if ss == \"zfs-pmem-rs_0-byp_0-nc_3\":\n",
    "        return \"zfs-pmem\"\n",
    "    if ss == \"zfs-lwb-rs_0\":\n",
    "        return \"zfs-lwb\"\n",
    "    if ss == \"zfs-sync_disabled-rs_0\":\n",
    "        return \"zfs-async\"\n",
    "    \n",
    "    # that's the default, other nc_* values will still show\n",
    "    ss = ss.replace(\"-nc_3\", \"\")\n",
    "    \n",
    "    # shorter name, already used in other parts of thesis text\n",
    "    ss = ss.replace(\"-sync_disabled\", \"-async\")\n",
    "    \n",
    "    for (z,zil) in itertools.product([\"zfs\", \"zvol\"], ['pmem', 'lwb', 'async']):\n",
    "        ss = ss.replace(f\"{z}-{zil}\", f\"{z}-{zil}\")\n",
    "    for flag in [\"rs\", \"byp\", \"nc\"]:\n",
    "        ss = ss.replace(f\"-{flag}\", f\",{flag}\")\n",
    "    ss = ss.replace(\"__on__\", \" on \")\n",
    "    \n",
    "    m = re.match(r\"(xfs|ext4)(.*)__dax_(False|True)\", ss)\n",
    "    if m:\n",
    "        dax = \"-dax\" if m[3] == \"True\" else \"\"\n",
    "        ss = f\"{m[1]}{dax}{m[2]}\"\n",
    "    \n",
    "    ss = ss.replace(\"_\", \"=\")\n",
    "    return ss\n",
    "\n",
    "list(map(rename_storage_stack, set(df['storage_stack'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_benchmarks(storage_stacks, baseline=None, _only_display_data=False, yticks_rel=None, barwidth=1000, display_tables=False, subplots_kw={}, allow_nc_neq_3=False, legend_ncol=2):\n",
    "    \n",
    "#     uncomment this if absolute values are of interest\n",
    "#     if baseline:\n",
    "#         compare_benchmarks(storage_stacks, baseline=None, _only_display_data=True, display_tables=display_tables, subplots_kw=subplots_kw)\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    # filter out sqlite-bench since it has no scaling factor\n",
    "    data = data.query('benchmark not in [\"sqlite-bench\"]').copy()\n",
    "    \n",
    "    # scale as specified\n",
    "    def scale_metric(row):\n",
    "        row['primary_metric_value'] = benchmark_scale_value(row['benchmark'], row['primary_metric_value'])\n",
    "        return row\n",
    "    data = data.apply(scale_metric,  axis=1, result_type='expand')\n",
    "    \n",
    "#     if not allow_nc_neq_3:\n",
    "#         data = data[data.storage_stack.map(lambda v: \"-nc_\" not in v or \"-nc_3\" in v)]\n",
    "\n",
    "    # filter storage stacks by parameter\n",
    "    data = data[data.storage_stack.map(lambda v: v in storage_stacks)]\n",
    "    \n",
    "    # now rename storage stacks\n",
    "    data['storage_stack'] = data.storage_stack.map(rename_storage_stack)\n",
    "    baseline = baseline if not baseline else rename_storage_stack(baseline)\n",
    "    \n",
    "    data = data.set_index(['benchmark', 'storage_stack', 'variable_value'], verify_integrity=True)\n",
    "    \n",
    "    tmp = data\n",
    "        \n",
    "    # only show 1, 4, 8\n",
    "    tmp = tmp.query('variable_value in [1, 4, 8]')\n",
    "        \n",
    "    if display_tables:\n",
    "        displaytable = tmp['primary_metric_value'].copy().unstack(\"benchmark\").reorder_levels(['variable_value', 'storage_stack']).sort_index()\n",
    "        display('displaytable:', displaytable)\n",
    "        if baseline:\n",
    "            display('1/displaytable', 1/displaytable)\n",
    "    \n",
    "    if _only_display_data:\n",
    "        return\n",
    "    \n",
    "    \n",
    "    storage_stacks = sorted(list(set(tmp.index.get_level_values('storage_stack'))))\n",
    "    variable_values = sorted(list(set(tmp.index.get_level_values('variable_value'))))\n",
    "    benchmarks = sorted(list(set(tmp.index.get_level_values('benchmark'))))\n",
    "    \n",
    "    color = {ss: sns.color_palette(None, n_colors=len(storage_stacks))[ssi] for ssi, ss in enumerate(storage_stacks)}\n",
    "        \n",
    "    subplots_kw = merge_dicts(dict(\n",
    "        figsize=(textwidth, 1*len(benchmarks)),\n",
    "        gridspec_kw={\"hspace\":0.25, 'wspace': 0.05}\n",
    "    ), subplots_kw)\n",
    "    \n",
    "    fig, axes = plt.subplots( len(benchmarks), len(variable_values), **subplots_kw)\n",
    "    \n",
    "    display(storage_stacks, variable_values, benchmarks)\n",
    "    \n",
    "    \n",
    "    # collect artists to draw legend (their color is fixed by the ax.bar call's color param)\n",
    "    most_recent_artists = {}\n",
    "    \n",
    "    for row, b in enumerate(benchmarks):\n",
    "        ylim=(0, 1.05 * tmp.loc[b, slice(None), slice(None)]['primary_metric_value'].max())\n",
    "        for col, vv in enumerate(variable_values):\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            ax.set_ylim(ylim)\n",
    "            \n",
    "            xwidth = 10\n",
    "            ax.set_xlim((-0.1*xwidth, xwidth *1.1))\n",
    "            \n",
    "            fontsize = 8\n",
    "            \n",
    "            \n",
    "            for si, ss in enumerate(storage_stacks):\n",
    "                try:\n",
    "                    x = si * xwidth/len(storage_stacks)\n",
    "                    x += 0.5 * xwidth/len(storage_stacks)\n",
    "                    \n",
    "                    y = tmp.loc[b, ss, vv]['primary_metric_value']\n",
    "                    barcontainer = ax.bar(x, y,\n",
    "                        label=ss,\n",
    "                        color=color[ss],\n",
    "                        width=min(\n",
    "                            fig.dpi_scale_trans.transform((barwidth, 0))[0],\n",
    "                            0.9 * xwidth /  len(storage_stacks)\n",
    "                            )\n",
    "                        )\n",
    "                    most_recent_artists[ss] = barcontainer\n",
    "                    assert(len(barcontainer.patches) == 1)\n",
    "                    bar = barcontainer.patches[0] # https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.Rectangle.html#matplotlib.patches.Rectangle\n",
    "                    \n",
    "                    if baseline:\n",
    "                        bl = tmp.loc[b, baseline, vv]['primary_metric_value']\n",
    "                        speedup = y / bl\n",
    "                        \n",
    "#                         print(b, vv, ss, bar.get_height(),  ax.transLimits.transform((0, y)))\n",
    "                        verticalalignment, ann_color = ('top', 'white') if ax.transLimits.transform((0, y))[1] > 0.5 else ('bottom', 'black')\n",
    "                        \n",
    "                        ax.annotate(speedup.round(2), (x, y),\n",
    "                                    horizontalalignment='center', verticalalignment=verticalalignment,\n",
    "                                    color=ann_color,\n",
    "                                    fontsize=fontsize, rotation=90)\n",
    "                except KeyError:\n",
    "                    pass # print(b, vv, ss)\n",
    "            \n",
    "            ax.set_xticklabels([]) # no meaning\n",
    "            \n",
    "            \n",
    "            if col == 0:\n",
    "                ax.set_ylabel(rename_benchmark(b), fontsize=fontsize, rotation=90)\n",
    "            \n",
    "            if col == len(variable_values) - 1:\n",
    "                ax.yaxis.tick_right()\n",
    "                ax.tick_params(labelsize=fontsize)\n",
    "                ax.yaxis.set_label_position(\"right\")\n",
    "                ax.set_ylabel(benchmark_unit(b), fontsize=fontsize, rotation=90)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "                \n",
    "            # 3 ticks on the y axis\n",
    "            ax.locator_params(axis='y', min_n_ticks=3)\n",
    "                \n",
    "            if row == 0:\n",
    "                assert round(vv) == vv\n",
    "                ax.set_title(f\"Scaling Factor {round(vv)}\", fontsize=fontsize)\n",
    "                \n",
    "    fig.legend(handles=list(most_recent_artists.values()), ncol=legend_ncol,\n",
    "               loc='center', bbox_to_anchor=(0.5, 0.075),\n",
    "               fontsize=7)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First take a hard look on `ncommitters`, `zvol_request_sync` and `bypass` to determine which we include in the subsequent graphs. This graph is not included in the publication.\n",
    "\n",
    "* nc3 vs nc4 (neighboring bars): hardly any difference, use nc3 because it's more cpu-efficient\n",
    "* rs0 vs rs1\n",
    "  * generally not much of a difference\n",
    "  * ext4 filebench-varmail performs significantly better with rs0 vs rs1\n",
    "* byp0 vs byp1: effect noticable at higher thread counts\n",
    "\n",
    "\n",
    "Note that the effect of ITXG bypass in the Block-Device-Proivder-Role is noticable but not significant (maybe this changes if we add a `fio` benchmark?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = {\n",
    "#  'ext4__on__devpmem__dax_False',\n",
    "#  'ext4__on__devpmem__dax_True',\n",
    "#  'ext4__on__dm-writecache__dax_False',\n",
    "#  'ext4__on__zvol-lwb-rs_0__dax_False',\n",
    "#  'ext4__on__zvol-lwb-rs_1__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_0-byp_0-nc_4__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_0-byp_1-nc_4__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_0-byp_1-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_0-nc_4__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_0-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_1-nc_4__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_1-nc_3__dax_False',\n",
    "#  'xfs__on__devpmem__dax_False',\n",
    "#  'xfs__on__devpmem__dax_True',\n",
    "#  'xfs__on__dm-writecache__dax_False',\n",
    "#  'xfs__on__zvol-lwb-rs_0__dax_False',\n",
    "#  'xfs__on__zvol-lwb-rs_1__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_0-byp_0-nc_4__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_0-byp_1-nc_4__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_0-byp_1-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_0-nc_4__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_0-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_1-nc_4__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_1-nc_3__dax_False',\n",
    "      \n",
    "#  'zfs-lwb-rs_0',\n",
    "#  'zfs-lwb-rs_1',\n",
    "#  'zfs-pmem-rs_0-byp_0-nc_2',\n",
    "#  'zfs-pmem-rs_0-byp_0-nc_3',\n",
    "#  'zfs-pmem-rs_0-byp_1-nc_2',\n",
    "#  'zfs-pmem-rs_0-byp_1-nc_3',\n",
    "#  'zfs-pmem-rs_1-byp_0-nc_2',\n",
    "#  'zfs-pmem-rs_1-byp_0-nc_3',\n",
    "#  'zfs-pmem-rs_1-byp_1-nc_2',\n",
    "#  'zfs-pmem-rs_1-byp_1-nc_3'\n",
    "}\n",
    "compare_benchmarks(list(tmp), baseline='ext4__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',\n",
    "                   subplots_kw={'figsize': (20,15)},\n",
    "                  allow_nc_neq_3=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = {\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_4',\n",
    " 'zfs-pmem-rs_0-byp_1-nc_3',\n",
    " 'zfs-pmem-rs_0-byp_1-nc_4',\n",
    " 'zfs-pmem-rs_1-byp_0-nc_3',\n",
    " 'zfs-pmem-rs_1-byp_0-nc_4',\n",
    " 'zfs-pmem-rs_1-byp_1-nc_3',\n",
    " 'zfs-pmem-rs_1-byp_1-nc_4'\n",
    "}\n",
    "compare_benchmarks(list(tmp), baseline='zfs-pmem-rs_0-byp_0-nc_3',\n",
    "                   subplots_kw={'figsize': (20,15)},\n",
    "                  allow_nc_neq_3=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Go with ncommitters = 3, but compare the different rs and byp settings later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZIL-PMEM vs ZIL-LWB\n",
    "\n",
    "* ZIL-PMEM outperforms ZIL-LWB in all workloads, and very significantly in most of them\n",
    "* ZIL-LWB throughput increases with growing `variable_value`\n",
    "* ZIL-PMEM is with one exception, less than 50% slower less than 50% slower than "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = {   \n",
    " 'zfs-lwb-rs_0',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',\n",
    "}\n",
    "compare_benchmarks(list(tmp), baseline='zfs-lwb-rs_0', barwidth=0.02, subplots_kw={\"figsize\": (0.8 * textwidth, 6) }, yticks_rel=[0,2,4,6,8], display_tables=True)\n",
    "dstools.savefig(\"appbench__zilpmem_vs_lwb\")\n",
    "# compare_benchmarks(list(tmp), display_tables=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZFS{lwb,pmem} with PMEM SLOG vs. ZFS-async vs. {ext4,xfs}{nodax,dax} only on PMEM\n",
    "\n",
    "* ZIL-PMEM has very high speedup over ZIL-LWB\n",
    "* In the small sync-IO heavy workloads (redis-SET, rocksdb-fillsync), ZIL-PMEM significantly outperforms the other candidates, even though they are PMEM only\n",
    "* For heavy sync IO (fio), the linux filesystems are better\n",
    "  * have significantly lower guarantees (no data journaling)\n",
    "* ext4 and xfs's DAX optimizations are significant\n",
    "* With one exception, ZIL-PMEM remains within 50% of `ZFS-async` performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = {\n",
    "    \n",
    " 'ext4__on__devpmem__dax_False',\n",
    " 'ext4__on__devpmem__dax_True',\n",
    "\n",
    " 'xfs__on__devpmem__dax_False',\n",
    " 'xfs__on__devpmem__dax_True',\n",
    "    \n",
    " 'zfs-lwb-rs_0',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',\n",
    "  'zfs-sync_disabled-rs_0',\n",
    "\n",
    "}\n",
    "compare_benchmarks(list(tmp), baseline='zfs-pmem-rs_0-byp_0-nc_3', display_tables=True, legend_ncol=3)\n",
    "dstools.savefig(\"appbench__zfs_vs_linuxfs_on_pmem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZVOLs + Linux Filesystem (zvol-lwb vs zvol-pmem with different zvrs,bypass settings)\n",
    "\n",
    "* ZIL-PMEM delivers significant speedup over ZIL-LWB\n",
    "* Effect of zvrs:\n",
    "    * neutral to negative for ZIL-LWB\n",
    "    * hugely beneficial for ZIL-PMEM\n",
    "        * warrants re-design of ZVOL (blk-mq, future work)\n",
    "* Effect of Bypass\n",
    "  * shows to some extent for xfs\n",
    "  * For ext4 in `filebench-oltp` at 8 threads, there is a huge decline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = {\n",
    "#  'ext4__on__dm-writecache__dax_False',\n",
    " 'ext4__on__zvol-lwb-rs_0__dax_False',\n",
    " 'ext4__on__zvol-lwb-rs_1__dax_False',\n",
    "    \n",
    " 'ext4__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_0-byp_1-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_0-nc_3__dax_False',\n",
    " 'ext4__on__zvol-pmem-rs_1-byp_1-nc_3__dax_False',\n",
    "    \n",
    "#  'xfs__on__dm-writecache__dax_False',\n",
    " 'xfs__on__zvol-lwb-rs_0__dax_False',\n",
    " 'xfs__on__zvol-lwb-rs_1__dax_False',\n",
    "    \n",
    " 'xfs__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_0-byp_1-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_0-nc_3__dax_False',\n",
    " 'xfs__on__zvol-pmem-rs_1-byp_1-nc_3__dax_False',\n",
    "    \n",
    "#   'xfs__on__zvol-sync_disabled-rs_0__dax_False',\n",
    "#   'ext4__on__zvol-sync_disabled-rs_0__dax_False',\n",
    "\n",
    "}\n",
    "\n",
    "compare_benchmarks(tmp, subplots_kw={'figsize': (15,12)})\n",
    "plt.show()\n",
    "\n",
    "# compare_benchmarks(list(filter(lambda s: \"ext4\" in s, tmp)), baseline='ext4__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False',  subplots_kw=subplots_kw)\n",
    "compare_benchmarks(list(filter(lambda s: \"xfs\" in s, tmp)), baseline='xfs__on__zvol-pmem-rs_0-byp_0-nc_3__dax_False', display_tables=True)\n",
    "dstools.savefig(\"appbench__xfs_zvol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp = tmp[(tmp.benchmark == 'fio-4k-sync-rand-write--size-per-job') | (tmp.benchmark ==  'fio-4k-sync-rand-write--size-div-by-numjobs') ]\n",
    "tmp = tmp[tmp.storage_stack.map(lambda r: \"xfs\" in r and \"zvol\" in r)]\n",
    "# display(tmp.columns)\n",
    "tmp = tmp.pivot(index=['benchmark', 'variable_value'], columns=['storage_stack'], values=['primary_metric_value']).T\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ZFS native to XFS on ZVOL (didn't lead anywhere)\n",
    "\n",
    "The idea was to show the benefits of ZFS's integrated design / support the claim for write amplification through the block-layer abstraction by example of `redis-SET` and `rocksdb-fillsync`.\n",
    "These benchmarks perform small writes but XFS, even though it writes a logical log internally, experiences write amplification because it only sees a block device instead of PMEM.\n",
    "\n",
    "=> By comparing ZFS (integrated, PMEM-aware design) vs ZVOL+XFS, we were hoping to see some constant relative speedup aat a given scaling factor. That was not the case, and it's probably due to bad assumptions. A better comparison would be XFS with Christoph Hellwig's incomplete DAX-aware logging patches. https://lkml.org/lkml/2020/9/17/77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "\n",
    "tmp = tmp.query('fstyp in [\"ext4\", \"xfs\", \"zfs-pmem\"]')\n",
    "tmp = tmp.query('fstyp != \"zfs-pmem\" or storage_stack == \"zfs-pmem-rs_0-byp_0-nc_3\"')\n",
    "tmp = tmp.set_index([\"fstyp\", \"daxmount\", \"blockdev_stack\", \"benchmark\", \"variable_value\"], verify_integrity=True)\n",
    "\n",
    "# tmp = tmp[[\"primary_metric_value\"]].unstack(\"daxmount\")\n",
    "# tmp = tmp.droplevel(0, axis=1)\n",
    "# tmp = tmp.dropna()\n",
    "display(set(tmp.index.get_level_values('blockdev_stack')))\n",
    "# display(tmp)\n",
    "# tmp = tmp.loc[slice(None), slice(None), [\"native\", \"devpmem\", \"zvol-pmem-rs_0-byp_0-nc_3\"], slice(None), slice(None)][[\"primary_metric_value\"]]\n",
    "# tmp.unstack(\"fstyp\").loc[slice(None), slice(None), ['rocksdb-fillsync', 'fio-4k-sync-rand-write--size-per-job']]\n",
    "# .loc[slice(None), slice(None), 'redis-SET', 1, ]\n",
    "tmp = tmp[['primary_metric_value']]\n",
    "# display(tmp.index)\n",
    "benches = ['rocksdb-fillsync', 'fio-4k-sync-rand-write--size-per-job']\n",
    "benches = slice(None)\n",
    "a = tmp.loc['zfs-pmem', slice(None), 'native', benches].unstack('benchmark')\n",
    "b = tmp.loc['xfs', slice(None), 'zvol-pmem-rs_0-byp_0-nc_3', benches].unstack('benchmark')\n",
    "display(a)\n",
    "display(b)\n",
    "a.droplevel([0])/b.droplevel([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> inconclusive, I expect that if we had `variable_values 1,2,3,4` we'd see  we'd see "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZFS vs. LinuxFS+dm-writecache\n",
    "\n",
    "* ZIL-PMEM has significantly better latency than dm-writecache\n",
    "* Scalability to higher concurrency/throughput: still better and/or comparable\n",
    "  * expect that at some point, high data rate / overwrite rate will make dm-writecache more efficient\n",
    "\n",
    "\n",
    "* (only need to look at zfs rs0 byp0 since neither are relevant for ZPL (only ZVOL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dm_writecache_benchmarks = {\n",
    " 'ext4__on__dm-writecache__dax_False',\n",
    " 'xfs__on__dm-writecache__dax_False',\n",
    " 'zfs-lwb-rs_0',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',    \n",
    "# 'zfs-sync_disabled-rs_0',\n",
    "}\n",
    "compare_benchmarks(list(dm_writecache_benchmarks), barwidth=0.015, subplots_kw={\"figsize\": (0.75*textwidth, 6)}, baseline='zfs-pmem-rs_0-byp_0-nc_3', display_tables=False)\n",
    "dstools.savefig(\"appbench__dm_writecache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The interesting absolute numbers for the Linux filesystems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp = tmp[tmp.storage_stack.map(lambda s: \"devpmem\" in s or \"writecache\" in s)]\n",
    "# tmp = tmp[tmp.storage_stack.map(lambda s: \"xfs\" in s)]\n",
    "tmp = tmp[tmp.storage_stack.map(lambda s: \"dax_\" in s)]\n",
    "tmp['dax'] = tmp.storage_stack.map(lambda s: s[s.find(\"dax_\"):])\n",
    "tmp['stack'] = tmp['blockdev_stack'] + '--' + tmp['dax']\n",
    "tmp['filesystem'] = tmp.storage_stack.map(lambda stack: stack[0:stack.find(\"_\")])\n",
    "tmp = tmp[tmp.benchmark.map(lambda s: \"redis\" in s or \"rocksdb\" in s or 'fio' in s)]\n",
    "tmp = tmp.set_index(['filesystem', 'stack', 'benchmark', 'variable_value'], verify_integrity=True)['primary_metric_value']\n",
    "# display(tmp)\n",
    "tmp = tmp.unstack(\"stack\")\n",
    "# tmp['delta_abs'] = tmp.devpmem - tmp['dm-writecache']\n",
    "# tmp['delta_rel'] = (tmp.devpmem / tmp['dm-writecache']).round(2)\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dm-writecache scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_stacks = {\n",
    " 'ext4__on__dm-writecache__dax_False',\n",
    " 'xfs__on__dm-writecache__dax_False',\n",
    "#  'ext4__on__devpmem__dax_False',\n",
    "#  'xfs__on__devpmem__dax_False',\n",
    "#  'ext4__on__devpmem__dax_True',\n",
    "#  'xfs__on__devpmem__dax_True',\n",
    " 'zfs-lwb-rs_0',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',        \n",
    "}\n",
    "\n",
    "benchmarks = [\n",
    "    'rocksdb-fillsync',\n",
    "    'fio-4k-sync-rand-write--size-per-job',\n",
    "]\n",
    "\n",
    "data = df.copy()\n",
    "data = data.set_index(['benchmark', 'storage_stack', 'variable_value'], verify_integrity=True)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "for col, b in enumerate(benchmarks):\n",
    "    tmp = data.copy()\n",
    "    tmp = tmp.loc[b, storage_stacks, slice(None)].droplevel(0).sort_index()\n",
    "    tmp = tmp['primary_metric_value'].unstack('variable_value')\n",
    "    tmp /= 1_000\n",
    "#     tmp = tmp.div(tmp[1.0], axis=0)\n",
    "#     ax = tmp.plot.barh(ax=axes[col], legend=False, xlim=(0,4.1), xticks=[0,1,2,3,4], title=b)\n",
    "    ax = tmp.plot.barh(ax=axes[col], legend=False, title=b)\n",
    "    if col != 0:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_ylabel(\"\")    \n",
    "\n",
    "# last ax is legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.2), title='variable value', ncol=3)\n",
    "# fig.suptitle(\"Speedup over variable_value=1\", fontsize=16)\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "#     plt.legend(loc='center left', title='variable value', bbox_to_anchor=(1, 0.5))\n",
    "#     plt.xlabel('Speedup')\n",
    "#     plt.title(f\"Speedup in IOPS for {benchmark}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_stacks = {\n",
    "#  'ext4__on__dm-writecache__dax_False',\n",
    " 'xfs__on__dm-writecache__dax_False',\n",
    "#  'ext4__on__devpmem__dax_False',\n",
    " 'xfs__on__devpmem__dax_False',\n",
    "#  'ext4__on__devpmem__dax_True',\n",
    " 'xfs__on__devpmem__dax_True',\n",
    "#  'zfs-lwb-rs_0',\n",
    " 'zfs-pmem-rs_0-byp_0-nc_3',        \n",
    "}\n",
    "\n",
    "benchmark = 'rocksdb-fillsync'\n",
    "benchmark = 'fio-4k-sync-rand-write--size-per-job'\n",
    "\n",
    "tmp = df.copy()\n",
    "tmp = tmp.set_index(['benchmark', 'storage_stack', 'variable_value'], verify_integrity=True)\n",
    "tmp = tmp.loc[benchmark, storage_stacks, slice(None)].droplevel(0).sort_index()\n",
    "tmp = tmp['primary_metric_value'].unstack('storage_stack')\n",
    "tmp /= 1_000\n",
    "tmp = tmp.plot.barh()\n",
    "plt.legend(loc='center left', title='storage stack', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('kIOPS')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumpster for some data analysis that didn't lead anywhere but that we don't want to delete ATM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp = tmp[tmp.storage_stack.map(lambda s: \"devpmem\" in s or \"writecache\" in s)]\n",
    "# tmp = tmp[tmp.storage_stack.map(lambda s: \"xfs\" in s)]\n",
    "tmp = tmp[tmp.storage_stack.map(lambda s: \"dax_\" in s)]\n",
    "tmp['dax'] = tmp.storage_stack.map(lambda s: s[s.find(\"dax_\"):])\n",
    "tmp = tmp[tmp.dax == \"dax_False\"]\n",
    "tmp['filesystem'] = tmp.storage_stack.map(lambda stack: stack[0:stack.find(\"_\")])\n",
    "tmp = tmp[tmp.benchmark.map(lambda s: \"redis\" in s or \"rocksdb\" in s)]\n",
    "tmp = tmp.set_index(['filesystem', 'blockdev_stack', 'benchmark', 'variable_value'], verify_integrity=True)['primary_metric_value']\n",
    "# display(tmp)\n",
    "tmp = tmp.unstack(\"blockdev_stack\")\n",
    "# tmp['delta_abs'] = tmp.devpmem - tmp['dm-writecache']\n",
    "tmp['delta_rel'] = (tmp.devpmem / tmp['dm-writecache']).round(2)\n",
    "display(tmp)\n",
    "tmp.loc[slice(None), 'redis-SET', :].plot.bar()\n",
    "print(tmp.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linux_filesystems = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp = tmp[tmp.storage_stack == \"zfs-sync_disabled-rs_0\"]\n",
    "tmp['stack'] = 'zfs'\n",
    "tmp['filesystem'] = 'zfs'\n",
    "tmp = tmp[tmp.benchmark.map(lambda s: \"redis\" in s or \"rocksdb\" in s)]\n",
    "tmp = tmp.set_index(['filesystem', 'stack', 'benchmark', 'variable_value'], verify_integrity=True)['primary_metric_value']\n",
    "# display(tmp)\n",
    "tmp = tmp.unstack(\"stack\")\n",
    "# tmp['delta_abs'] = tmp.devpmem - tmp['dm-writecache']\n",
    "# tmp['delta_rel'] = (tmp.devpmem / tmp['dm-writecache']).round(2)\n",
    "display(tmp)\n",
    "tmp.loc[slice(None), 'redis-SET', :].plot.bar()\n",
    "print(tmp.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfs = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = pd.concat([linux_filesystems, zfs])\n",
    "display(tmp)\n",
    "tmp.loc[slice(None), 'rocksdb-fillsync', :].plot.bar(figsize=(10, 10))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
