{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_row_dict(output_json):\n",
    "    r = {}\n",
    "    for k, v in dotted.get(output_json, \"latency_analysis\").items():\n",
    "        assert k[0] == '@'\n",
    "        k = k[1:] # strip leading @\n",
    "        assert k not in r\n",
    "        r[k] = v\n",
    "    \n",
    "    r = {\n",
    "        \"numjobs\": int(dotted.get(output_json, \"fio_config.numjobs\")),\n",
    "        **r\n",
    "    }\n",
    "    return r\n",
    "\n",
    "rows = [to_row_dict(j) for j in result_storage.iter_results(\"latency_analysis\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(\"numjobs\")\n",
    "df = df.sort_index()\n",
    "# display(df)\n",
    "display(df / 1_000_000)\n",
    "# compute zfs write breakdown\n",
    "\n",
    "# zfs_write = ASYNC + zfs_log_write_{begin,end} + zil_commit\n",
    "# zil_commit = ZIL_LWB_OTHER +  zillwb_commit_waiter__timeout  + zillwb_commit_waiter__issue\n",
    "# zillwb_commit_waiter__issue = ZIL_LWB_ZIOWAIT + pmem_submit_bio\n",
    "df[\"zio\"] = df.zillwb_commit_waiter__issue - df.pmem_submit_bio\n",
    "df[\"zil-lwb-other\"] = df.zil_commit - df.zillwb_commit_waiter__timeout - df.zillwb_commit_waiter__issue\n",
    "df[\"itx\"] = df.zfs_log_write_begin + df.zfs_log_write_finish\n",
    "df[\"async\"] = df.zfs_write - df.itx - df.zil_commit\n",
    "# cosmetics\n",
    "df[\"zil-lwb-fill-timeout\"] = df.zillwb_commit_waiter__timeout\n",
    "df[\"zil-lwb-ziowait\"] = df.zillwb_commit_waiter__issue - df.pmem_submit_bio\n",
    "\n",
    "# df[\"pmem\"] = df[\"pmem_submit_bio\"]\n",
    "# # df[\"zio\"] = df[\"zio_rewrite\"] - df[\"pmem\"]\n",
    "# df[\"zil-lwb-fill-timeout\"] = df[\"zillwb_commit_waiter__timeout\"]\n",
    "# df[\"zil-lwb-ziowait\"] = df[\"zillwb_commit_waiter__issue\"]\n",
    "# df[\"zil-lwb-other\"] = df[\"zil_commit\"] - df[\"zil-lwb-ziowait\"] - df[\"zil-lwb-fill-timeout\"]\n",
    "# df[\"itx\"] = df[\"zfs_log_write_begin\"] + df[\"zfs_log_write_finish\"]\n",
    "# df[\"async\"] = df[\"zfs_write\"] - (df[\"itx\"] + df[\"\"])\n",
    "\n",
    "df[\"zfs_write__lat_avg\"] = df[\"zfs_write\"] / df[\"zfs_write_count\"]\n",
    "display(df.zfs_write__lat_avg)\n",
    "\n",
    "\n",
    "# zfs_write_comps = [\"async\", \"itx\", \"zil\", \"zio\", \"pmem\"]\n",
    "zfs_write_comps = [ \"async\", \"itx\", \"zil-lwb-other\", \"zil-lwb-fill-timeout\", \"zil-lwb-ziowait\", \"pmem_submit_bio\"]\n",
    "\n",
    "# add `unaccounted` component\n",
    "tmp = df.filter(zfs_write_comps, axis=1)\n",
    "# display(tmp)\n",
    "tmp = tmp.transpose().sum()\n",
    "# display(tmp)\n",
    "df[\"unaccounted\"] = df[\"zfs_write\"] - tmp\n",
    "zfs_write_comps += [\"unaccounted\"]\n",
    "\n",
    "# relative breakdown (the raw data is aggregate wall-clock time spent in the functions,\n",
    "# not-so-precise cpaturing interval)\n",
    "\n",
    "pdata = df.filter(zfs_write_comps, axis=1)\n",
    "display(pdata / 1_000_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_breakdown(pdata, title, figname, datalabel=None):\n",
    "    figsize = (14, 10)\n",
    "    ax = pdata.plot.area(stacked=True, figsize=figsize, sort_columns=True)\n",
    "    ax.set_title(title, pad=16)\n",
    "    ax.set_ylabel(datalabel)\n",
    "    ax.set_xlabel(\"numjobs\")\n",
    "    \n",
    "    ax.set_xticks(pdata.index)\n",
    "    ax.set_xticklabels(pdata.index, rotation=0) # for some reason pandas draws the xlabels rotated\n",
    "    \n",
    "    #     ax.set_yticklabels([]) # shows '0' which is confusing unless we have multiple numjobs values\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "    dstools.savefig(f\"latency_breakdown_stacked-{figname}\")\n",
    "\n",
    "    # Code for plotting individual bars\n",
    "    #     ax = pdata.plot.bar(stacked=False, figsize=figsize, sort_columns=True)\n",
    "    #     ax.set_title(title, pad=16)\n",
    "    #     ax.set_xlabel(xlabel)\n",
    "    #     ax.legend(bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "    #     savefig(f\"latency_breakdown_individual_bars-{figname}\")\n",
    "    \n",
    "title = \"zfs_write() relative latency breakdown (sampling overhead!)\"\n",
    "rpdata = pdata.div(df[\"zfs_write\"], axis=0)\n",
    "display((rpdata * 100).round(1))\n",
    "plot_breakdown(rpdata, title, \"relative\")\n",
    "\n",
    "\n",
    "title = \"zfs_write() absolute latency breakdown (sampling overhead!)\"\n",
    "apdata = pdata.div(df[\"zfs_write\"], axis=0).mul(df.zfs_write__lat_avg, axis=0)\n",
    "display((apdata/1000).round(1))\n",
    "plot_breakdown(apdata, title, \"absolute\", datalabel=\"nano seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import devdax write latencies from perf analysis\n",
    "export = '{\"schema\":{\"fields\":[{\"name\":\"numjobs\",\"type\":\"integer\"},{\"name\":\"w_lat_mean\",\"type\":\"number\"}],\"primaryKey\":[\"numjobs\"],\"pandas_version\":\"0.20.0\"},\"data\":[{\"numjobs\":5,\"w_lat_mean\":4603.755736},{\"numjobs\":1,\"w_lat_mean\":617.493467},{\"numjobs\":3,\"w_lat_mean\":2649.305724},{\"numjobs\":15,\"w_lat_mean\":40203.617083},{\"numjobs\":4,\"w_lat_mean\":3577.32901},{\"numjobs\":7,\"w_lat_mean\":6599.553758},{\"numjobs\":10,\"w_lat_mean\":16968.396836},{\"numjobs\":8,\"w_lat_mean\":8479.026951},{\"numjobs\":13,\"w_lat_mean\":29632.536489},{\"numjobs\":2,\"w_lat_mean\":1684.654042},{\"numjobs\":11,\"w_lat_mean\":22418.170104},{\"numjobs\":9,\"w_lat_mean\":12462.04705},{\"numjobs\":12,\"w_lat_mean\":26023.822275},{\"numjobs\":14,\"w_lat_mean\":34184.87662},{\"numjobs\":6,\"w_lat_mean\":5674.396315}]}'\n",
    "devdax_write_latencies = pd.read_json(export, orient=\"table\")\n",
    "display(devdax_write_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odata = apdata.copy() #! apdata from previous run\n",
    "odata[\"devdax_w_lat_mean\"] = devdax_write_latencies[\"w_lat_mean\"]\n",
    "optimal_zfs_write_comps = [\"async\", \"itx\", \"devdax_w_lat_mean\"]\n",
    "odata.filter(optimal_zfs_write_comps).plot.area(stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opportunities = pd.DataFrame.from_dict({\n",
    "    \"current\": apdata.filter(zfs_write_comps).sum(axis=1),\n",
    "    \"optimal\": odata.filter(optimal_zfs_write_comps).sum(axis=1),\n",
    "})\n",
    "opportunities.plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = 1/opportunities.div(opportunities.current, axis=0)\n",
    "speedup.plot.line(title=\"Potential Speedup (baseline: current)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
