{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "#     ('result.identity', \"benchmark\", str),  \n",
    "    (\"storage_stack.identity\", \"storage_stack\", str),\n",
    "    (\"result.fio_config.numjobs\", \"numjobs\", int),\n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return {\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def to_row_dict(output_json):\n",
    "    try:\n",
    "        r = {}\n",
    "        for k, v in dotted.get(output_json, \"result.latency_analysis\").items():\n",
    "            assert k[0] == '@'\n",
    "            k = k[1:] # strip leading @\n",
    "            assert k not in r\n",
    "            r[k] = v\n",
    "\n",
    "        r = {\n",
    "            **extract_id_var_values(output_json),\n",
    "            \"fio_metrics\": get_fio_write_metrics(output_json['result']),\n",
    "            \n",
    "            # cpu stats\n",
    "            \"cpu\": output_json[\"result\"][\"cpu_time\"][\"allcpu\"],\n",
    "            **r,\n",
    "        }\n",
    "        return r\n",
    "    except:\n",
    "        print(json.dumps(output_json))\n",
    "        raise\n",
    "\n",
    "rows = [to_row_dict(j) for j in result_storage.iter_results(\"zillwb_latency_analysis__v3\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars)\n",
    "df = df.sort_index()\n",
    "display(df)\n",
    "# display(df / 1_000_000)\n",
    "# compute zfs write breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate FIO and CPU Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "df_fio = tmp['fio_metrics'].apply(pd.Series)\n",
    "df_fio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "tmp = tmp['cpu'].apply(pd.Series)\n",
    "display(tmp)\n",
    "# display(tmp)\n",
    "cpu_total = tmp.sum(axis=1)\n",
    "tmp['not_idle'] = cpu_total - tmp.idle\n",
    "# second socket was disabled => half of total cpu time is idle time\n",
    "tmp['utilization'] = tmp.not_idle / (cpu_total - (cpu_total/2))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove `fio_metrics` and `cpu` from `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['fio_metrics']\n",
    "del df['cpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show that LWB merging is not a thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "data = tmp[[\"zfs_write_count\", \"lwb_issue_count\"]]\n",
    "display(data)\n",
    "data.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ZIO + PMEM latency when writing LWBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "\n",
    "tmp['interpolated_lwb_write_time'] = tmp.lwb_issue_count * tmp.last_lwb_latency\n",
    "\n",
    "tmp['zio_overhead'] = tmp.interpolated_lwb_write_time - tmp.pmem_submit_bio\n",
    "\n",
    "# display(tmp[[\"zfs_write_count\", \"lwb_issue_count\"]])\n",
    "\n",
    "data = tmp[[\n",
    "    \"zio_overhead\",\n",
    "    \"pmem_submit_bio\",\n",
    "]]\n",
    "lwb_write_time = data\n",
    "display(lwb_write_time)\n",
    "\n",
    "ax = lwb_write_time.plot.bar(stacked=True, figsize=(10,5))\n",
    "ax.set_title(\"Interpolated LWB Write Time\")\n",
    "\n",
    "# TODO: does this make sense?\n",
    "lwb_write_time_by_iops = lwb_write_time.div(df_fio.w_iops_mean, axis=0)\n",
    "lwb_write_time_by_iops.plot.bar(stacked=True, figsize=(10,5)).set_title(\"Interpolated LWB Write Time By IOPS\")\n",
    "\n",
    "\n",
    "numjobs = zio_overhead_vs_pmem_time.index.to_frame()['numjobs']\n",
    "display(numjobs)\n",
    "lwb_write_time_by_numjobs = zio_overhead_vs_pmem_time.div(numjobs, axis=0)\n",
    "ax = lwb_write_time_by_numjobs.plot.bar(stacked=True, figsize=(10,5))\n",
    "ax.set_title(\"Interpolated LWB Write Time, By Numjobs\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "\n",
    "write_count = tmp['zfs_write_count']\n",
    "del tmp['zfs_write_count']\n",
    "\n",
    "tmp['interpolated_lwb_write_time'] = tmp.lwb_issue_count * tmp.last_lwb_latency\n",
    "del tmp['last_lwb_latency']\n",
    "del tmp['lwb_issue_count']\n",
    "\n",
    "tmp['zio_overhead'] = tmp.interpolated_lwb_write_time - tmp.pmem_submit_bio\n",
    "\n",
    "tmp['async'] = tmp.zfs_write - tmp.zil_commit - tmp.zfs_log_write\n",
    "tmp['zil_lwb_overhead'] = tmp.zil_commit - (\n",
    "    tmp.zil_fill_commit_list \n",
    "    + tmp.zillwb_commit_waiter__issue_cv\n",
    "    + tmp.zillwb_commit_waiter__timeout_cv\n",
    "    + tmp.zillwb_lwb_write_issue\n",
    "#     + tmp.zio_overhead\n",
    "#     + tmp.pmem_submit_bio\n",
    ")\n",
    "\n",
    "data = tmp[[\n",
    "    \"async\",\n",
    "    \"zfs_log_write\",\n",
    "    \"zil_fill_commit_list\",\n",
    "    \"zil_lwb_overhead\",\n",
    "    \"zillwb_lwb_write_issue\",\n",
    "    \"zillwb_commit_waiter__issue_cv\",\n",
    "    \"zillwb_commit_waiter__timeout_cv\",\n",
    "#     \"zillwb_remaining_overhead\",\n",
    "#     \"zio_overhead\",\n",
    "#     \"pmem_submit_bio\",\n",
    "]]\n",
    "df_latbreakdown = data\n",
    "df_latbreakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  All In One Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relbreakdown = df_latbreakdown.copy()\n",
    "\n",
    "total = relbreakdown.sum(axis=1)\n",
    "display(relbreakdown)\n",
    "relbreakdown = relbreakdown.div(total, axis=0)\n",
    "# display(relbreakdown)\n",
    "\n",
    "abs_by_iops = df_latbreakdown.div(df_fio.w_iops_mean, axis=0)\n",
    "\n",
    "measurement_error = df_fio.w_lat_mean - abs_by_iops.copy().sum(axis=1)\n",
    "\n",
    "\n",
    "rows = [\n",
    "    \"relbreakdown\",\n",
    "    \"abs_by_iops\",\n",
    "    \"fio_latency\",\n",
    "    \"measurement_error\",\n",
    "    \"lwb_write_time_by_iops\",\n",
    "    \"lwb_write_time_by_numjobs\",\n",
    "    \n",
    "#     \"iops\",\n",
    "#     \"latency_std\",\n",
    "]\n",
    "nrows = len(rows)\n",
    "ncols = 1\n",
    "g, axes = plt.subplots(nrows, ncols, squeeze=False, figsize=(7.5 * ncols ,5 * nrows), gridspec_kw = {'hspace': 0.4})\n",
    "for row in range(0, nrows):\n",
    "    for col in range(0, ncols):\n",
    "        \n",
    "        storage_stack = {\n",
    "            0: 'zfs-lwb-rs_0',\n",
    "        }[col]\n",
    "        \n",
    "        row_name = rows[row]\n",
    "       \n",
    "        \n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        try:\n",
    "\n",
    "            if row_name == \"relbreakdown\":\n",
    "                relbreakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 1.1), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"abs_by_iops\":\n",
    "                abs_by_iops.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"iops\":\n",
    "                df_fio.loc[storage_stack, \"w_iops_mean\"].plot(ax=ax)\n",
    "            elif row_name == \"fio_latency\":\n",
    "                df_fio.loc[storage_stack, \"w_lat_mean\"].plot.bar(ax=ax)\n",
    "            elif row_name == \"latency_std\":\n",
    "                df_fio.loc[storage_stack, \"w_lat_stddev\"].plot(ax=ax)\n",
    "            elif row_name == \"measurement_error\":\n",
    "                measurement_error.loc[storage_stack, ].plot.bar(ax=ax)\n",
    "            elif row_name == \"lwb_write_time_by_numjobs\":\n",
    "                lwb_write_time_by_numjobs.loc[storage_stack, ].plot.bar(ax=ax, stacked=True)\n",
    "            elif row_name == \"lwb_write_time_by_iops\":\n",
    "                lwb_write_time_by_iops.loc[storage_stack, ].plot.bar(ax=ax, stacked=True)\n",
    "            else:\n",
    "                raise Exception(f\"unknown row name {row_name}\")\n",
    "            ax.set_title(f\"{row_name}\")\n",
    "        \n",
    "        except:\n",
    "            print(row_name)\n",
    "            raise\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
