{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def filter_by_index_value(df, level, filter):\n",
    "    \"\"\"Return a new df that only contains rows whose MultiIndex column `level`'s value passes `filter`\"\"\"\n",
    "    return df[df.index.get_level_values(level).map(filter)]\n",
    "\n",
    "def remove_index_dimension(df, level, value):\n",
    "    \"\"\"Reduce dimensionality of a dataframe by filtering by and subsequently dropping one of its index levels.\n",
    "    \n",
    "    df is assumed to be a multi-indexed pd.DataFrame.\n",
    "    First, filter the data frame so that we only keep rows whose index tuple has value `value` at level `level`.\n",
    "    Now the resulting data frame only has a single value at the level.\n",
    "    Thus remove that level from the index.\n",
    "    Voila: dimensionality reduced.\n",
    "    \"\"\"\n",
    "    df = df[df.index.get_level_values(level) == value]\n",
    "    assert set(df.index.get_level_values(level)) == {value}\n",
    "    df.index = df.index.droplevel(level)\n",
    "    return df\n",
    "\n",
    "def _test_remove_index_dimension():\n",
    "    data = [{\"favnum\": n, \"favletter\": l, \"id\": id} for id, (n, l) in enumerate(itertools.product([23,42],[\"a\", \"b\"]))]\n",
    "    d = pd.DataFrame(data).set_index([\"favnum\", \"favletter\"])\n",
    "    display(d)\n",
    "    display(remove_index_dimension(d, \"favnum\", 23))\n",
    "    display(remove_index_dimension(d, \"favletter\", \"b\"))\n",
    "    \n",
    "_test_remove_index_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_values_sorted_unique(df, level):\n",
    "    \"\"\"Returns the sorted unique values of a DataFrame's multi-index at level `level`\"\"\"\n",
    "    return sorted(list(set(df.index.get_level_values(level))))\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "class FactorizedDataFrameItem(AttrDict):\n",
    "    @property\n",
    "    def title(self):\n",
    "        if self.fdf.row and self.fdf.col:\n",
    "            return f\"{self.fdf.row}={self.rv}|{self.fdf.col}={self.cv}\"\n",
    "        elif self.fdf.row:\n",
    "            return f\"{self.fdf.row}={self.rv}\"\n",
    "        elif self.fdf.col:\n",
    "            return f\"{self.fdf.col}={self.cv}\"\n",
    "        else:\n",
    "            return \"\"\n",
    "            \n",
    "        \n",
    "class FactorizedDataFrame:\n",
    "    def __init__(self, data, row, col):\n",
    "        self.data = data\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "\n",
    "        self.col_values = [None] if not self.col else level_values_sorted_unique(self.data, self.col)\n",
    "        self.row_values = [None] if not self.row else level_values_sorted_unique(self.data, self.row)\n",
    "        \n",
    "    def iter_factorized(self):\n",
    "        for ci, c in enumerate(self.col_values):\n",
    "            for ri, r in enumerate(self.row_values):\n",
    "                d = self.data.copy()\n",
    "                if c:\n",
    "                    d = remove_index_dimension(d, self.col, c)\n",
    "                if r:\n",
    "                    d = remove_index_dimension(d, self.row, r)\n",
    "                # display(d)\n",
    "            \n",
    "                context = FactorizedDataFrameItem({\n",
    "                    \"fdf\": self,\n",
    "                    \"d\": d,\n",
    "                    \"ri\": ri,\n",
    "                    \"rv\": r,\n",
    "                    \"ci\": ci,\n",
    "                    \"cv\": c,\n",
    "                    \"is_last_row\": ri == len(self.row_values)-1,\n",
    "                    \"is_last_col\": ci == len(self.col_values)-1,\n",
    "                })\n",
    "                yield context\n",
    "                \n",
    "\n",
    "def factorplot(data=None, row=None, col=None, plot=None, subplots_kw={}):\n",
    "    \"\"\"Factorizez MultiIndex'ed DataFrame `data`, then invokes `plot` for each FactorizedDataFrameItem\"\"\"\n",
    "    \n",
    "    fdf = FactorizedDataFrame(data, row, col)\n",
    "    \n",
    "    subplots_kw = {\n",
    "        \"gridspec_kw\": {'hspace': 1},\n",
    "        **subplots_kw,\n",
    "        \"squeeze\": False, # axes should always be two-dimensional\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(len(fdf.row_values), len(fdf.col_values), **subplots_kw)\n",
    "\n",
    "    for f in fdf.iter_factorized():\n",
    "        ax = axes[f.ri, f.ci]\n",
    "        ax.set_title(f.title)\n",
    "        legend = f.ri == len(fdf.row_values)-1 and f.ci == len(fdf.col_values)-1\n",
    "        plot(f, ax, legend)\n",
    "        if legend:\n",
    "            plt.legend(loc='lower left', bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "#     ('result.identity', \"benchmark\", str),  \n",
    "    (\"storage_stack.identity\", \"storage_stack\", str),\n",
    "    (\"result.fio_config.numjobs\", \"numjobs\", int),\n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return {\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def to_row_dict(output_json):\n",
    "    try:\n",
    "        r = {}\n",
    "        for k, v in dotted.get(output_json, \"result.latency_analysis\").items():\n",
    "            assert k[0] == '@'\n",
    "            k = k[1:] # strip leading @\n",
    "            assert k not in r\n",
    "            r[k] = v\n",
    "\n",
    "        r = {\n",
    "            **extract_id_var_values(output_json),\n",
    "            \"fio_metrics\": get_fio_write_metrics(output_json['result']),\n",
    "            **r,\n",
    "        }\n",
    "        return r\n",
    "    except:\n",
    "        print(json.dumps(output_json))\n",
    "        raise\n",
    "\n",
    "rows = [to_row_dict(j) for j in result_storage.iter_results(\"comparison_zil_overhead_lwb_vs_pmem__v2\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars)\n",
    "df = df.sort_index()\n",
    "display(df)\n",
    "# display(df / 1_000_000)\n",
    "# compute zfs write breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "\n",
    "del tmp['fio_metrics']\n",
    "\n",
    "write_count = tmp['zfs_write_count']\n",
    "del tmp['zfs_write_count']\n",
    "\n",
    "tmp['async'] = tmp.zfs_write - tmp.zil_commit - tmp.zfs_log_write\n",
    "tmp['zil_persistence'] = tmp.zil_commit - tmp.zil_fill_commit_list\n",
    "\n",
    "data = tmp[[\"async\", \"zfs_log_write\", \"zil_fill_commit_list\", \"zil_persistence\"]]\n",
    "df_latbreakdown = data\n",
    "df_latbreakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "df_fio = tmp['fio_metrics'].apply(pd.Series)\n",
    "df_fio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Latency Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df_latbreakdown.copy()\n",
    "total = data.sum(axis=1)\n",
    "# display(data)\n",
    "# display(total)\n",
    "data = data.div(total, axis=0)\n",
    "# display(data)\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "    f.d.plot.bar(ax=ax, ylim=(0, 1.1), legend=legend, stacked=True)\n",
    "    if not f.is_last_row:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    \n",
    "factorplot(data, row='storage_stack', col=None, plot=plot, subplots_kw={\n",
    "    \"figsize\": (10, 10),\n",
    "    \"gridspec_kw\": {'hspace': 0.2},\n",
    "})\n",
    "\n",
    "# data.loc[\"zfs-lwb-rs_0\", ].plot.area(**kwargs)\n",
    "# data.loc[\"zfs-pmem-rs_0-byp_0-nc_3\", ].plot.area(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute Latency Normalized By IOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_latbreakdown.div(df_fio.w_iops_mean, axis=0)\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "    f.d.plot.bar(ax=ax, ylim=(0, 80_000), legend=legend, stacked=True)\n",
    "    if not f.is_last_row:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    \n",
    "factorplot(data, row='storage_stack', col=None, plot=plot, subplots_kw={\n",
    "    \"figsize\": (10, 10),\n",
    "    \"gridspec_kw\": {'hspace': 0.2},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fio-perceived IOPS and Latency For Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_fio.w_lat_mean.unstack(\"storage_stack\").plot.bar(figsize=(10,5), subplots=True, yticks=range(0, 100_000, 20_000))\n",
    "ax = df_fio.w_lat_mean.unstack(\"storage_stack\").plot(figsize=(10,5))\n",
    "ax.legend(bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_fio.w_iops_mean.unstack(\"storage_stack\").plot.bar(figsize=(10,5), subplots=True)\n",
    "ax = df_fio.w_iops_mean.unstack(\"storage_stack\").plot(figsize=(10,5))\n",
    "ax.legend(bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Fio And Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_latbreakdown.div(df_fio.w_iops_mean, axis=0)\n",
    "total_measured = data.sum(axis=1)\n",
    "total_measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fio.w_lat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_fio.w_lat_mean - total_measured).unstack(\"storage_stack\").plot.bar(figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.bar(figsize=(10,5), subplots=True, yticks=range(0, 100_000, 20_000))\n",
    "\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "    f.d.plot.bar(ax=ax, ylim=(0, 80_000), legend=legend, stacked=True)\n",
    "    if not f.is_last_row:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    \n",
    "factorplot(data, row='storage_stack', col=None, plot=plot, subplots_kw={\n",
    "    \"figsize\": (10, 10),\n",
    "    \"gridspec_kw\": {'hspace': 0.2},\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
