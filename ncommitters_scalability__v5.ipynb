{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog\n",
    "\n",
    "* v5:\n",
    "  * new dataset with longer-running fio benchmarks (`runtime_seconds=60`)\n",
    "  * => CPU times shifted a little upwards, probably due to zio background work\n",
    "  * played around with log scales for latency and pmem time, found it more confusing than useful though\n",
    "    * => commented out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_storage_prefix = \"ncommitters_scalability__v5\"\n",
    "\n",
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "    ('pmem_setup_data.interleaving', \"interleaving\", int),    \n",
    "    (\"storage_stack.config.module_args.zfs.zfs_zil_pmem_prb_ncommitters\", \"ncommitters\", int),\n",
    "    (\"fio_config.numjobs\", \"numjobs\", int),\n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return jw\n",
    "\n",
    "def to_unified_dict(output_json):\n",
    "    d = output_json\n",
    "    \n",
    "    try:\n",
    "        jw = get_fio_write_metrics(output_json)\n",
    "\n",
    "        return {\n",
    "            **extract_id_var_values(output_json),\n",
    "\n",
    "            # fio\n",
    "            \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "            \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "            \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "            \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "\n",
    "            # kstats\n",
    "            **d[\"zvol_stats\"],\n",
    "            **d[\"itxg_bypass_stats\"],\n",
    "            **d[\"zil_pmem_stats\"],\n",
    "            **d[\"zil_pmem_ringbuf_stats\"],\n",
    "            \"bio_total\": d[\"zvol_stats\"][\"submit_bio__zvol_write(with_taskq_if_enabled)\"],\n",
    "            \"taskq_delay\": dotted.get(d, 'zvol_stats.zvol_write__taskq_qdelay'),\n",
    "            \"assign_aquire\": dotted.get(d, 'itxg_bypass_stats.assign__aquisition_total'),\n",
    "            \"assign_vtable\": dotted.get(d, 'itxg_bypass_stats.assign__vtable'),\n",
    "            \"assign_total\": dotted.get(d, 'itxg_bypass_stats.assign__total'),\n",
    "            \"commit_total\": dotted.get(d, 'itxg_bypass_stats.commit__total'),\n",
    "            \"commit_aquire\": dotted.get(d, 'itxg_bypass_stats.commit__aquire'),\n",
    "\n",
    "            # cpu stats\n",
    "            **{f\"cpu_{comp}\": val for comp, val in dotted.get(d, \"cpu_time.allcpu\").items()},\n",
    "        }\n",
    "    except Exception as e:\n",
    "        import json\n",
    "        print(json.dumps(output_json))\n",
    "        raise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [{**to_unified_dict(j)} for j in result_storage.iter_results(result_storage_prefix)]\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars, verify_integrity=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-process cpu utilization\n",
    "tmp = df.filter(regex=\"^cpu_.*\", axis=1)\n",
    "# display(tmp)\n",
    "cpu_total = tmp.sum(axis=1)\n",
    "df['cpu_not_idle'] = cpu_total - df.cpu_idle\n",
    "# second socket was disabled => half of total cpu time is idle time\n",
    "df['cpu_utilization'] = df.cpu_not_idle / (cpu_total - (cpu_total/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FactorizedDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def filter_by_index_value(df, level, filter):\n",
    "    \"\"\"Return a new df that only contains rows whose MultiIndex column `level`'s value passes `filter`\"\"\"\n",
    "    return df[df.index.get_level_values(level).map(filter)]\n",
    "\n",
    "def remove_index_dimension(df, level, value):\n",
    "    \"\"\"Reduce dimensionality of a dataframe by filtering by and subsequently dropping one of its index levels.\n",
    "    \n",
    "    df is assumed to be a multi-indexed pd.DataFrame.\n",
    "    First, filter the data frame so that we only keep rows whose index tuple has value `value` at level `level`.\n",
    "    Now the resulting data frame only has a single value at the level.\n",
    "    Thus remove that level from the index.\n",
    "    Voila: dimensionality reduced.\n",
    "    \"\"\"\n",
    "    df = df[df.index.get_level_values(level) == value]\n",
    "    assert set(df.index.get_level_values(level)) == {value}\n",
    "    df.index = df.index.droplevel(level)\n",
    "    return df\n",
    "\n",
    "def _test_remove_index_dimension():\n",
    "    data = [{\"favnum\": n, \"favletter\": l, \"id\": id} for id, (n, l) in enumerate(itertools.product([23,42],[\"a\", \"b\"]))]\n",
    "    d = pd.DataFrame(data).set_index([\"favnum\", \"favletter\"])\n",
    "    display(d)\n",
    "    display(remove_index_dimension(d, \"favnum\", 23))\n",
    "    display(remove_index_dimension(d, \"favletter\", \"b\"))\n",
    "    \n",
    "_test_remove_index_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_values_sorted_unique(df, level):\n",
    "    \"\"\"Returns the sorted unique values of a DataFrame's multi-index at level `level`\"\"\"\n",
    "    return sorted(list(set(df.index.get_level_values(level))))\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "class FactorizedDataFrameItem(AttrDict):\n",
    "    @property\n",
    "    def title(self):\n",
    "        if self.fdf.row and self.fdf.col:\n",
    "            return f\"{self.fdf.row}={self.rv}|{self.fdf.col}={self.cv}\"\n",
    "        elif self.fdf.row:\n",
    "            return f\"{self.fdf.row}={self.rv}\"\n",
    "        elif self.fdf.col:\n",
    "            return f\"{self.fdf.col}={self.cv}\"\n",
    "        else:\n",
    "            return \"\"\n",
    "            \n",
    "        \n",
    "class FactorizedDataFrame:\n",
    "    def __init__(self, data, row, col):\n",
    "        self.data = data\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "\n",
    "        self.col_values = [None] if not self.col else level_values_sorted_unique(self.data, self.col)\n",
    "        self.row_values = [None] if not self.row else level_values_sorted_unique(self.data, self.row)\n",
    "        \n",
    "    def iter_factorized(self):\n",
    "        for ci, c in enumerate(self.col_values):\n",
    "            for ri, r in enumerate(self.row_values):\n",
    "                d = self.data.copy()\n",
    "                if c:\n",
    "                    d = remove_index_dimension(d, self.col, c)\n",
    "                if r:\n",
    "                    d = remove_index_dimension(d, self.row, r)\n",
    "                # display(d)\n",
    "            \n",
    "                context = FactorizedDataFrameItem({\n",
    "                    \"fdf\": self,\n",
    "                    \"d\": d,\n",
    "                    \"ri\": ri,\n",
    "                    \"rv\": r,\n",
    "                    \"ci\": ci,\n",
    "                    \"cv\": c,\n",
    "                    \"is_last_row\": ri == len(self.row_values)-1,\n",
    "                    \"is_last_col\": ci == len(self.col_values)-1,\n",
    "                })\n",
    "                yield context\n",
    "                \n",
    "\n",
    "def factorplot(data=None, row=None, col=None, plot=None, subplots_kw={}):\n",
    "    \"\"\"Factorizez MultiIndex'ed DataFrame `data`, then invokes `plot` for each FactorizedDataFrameItem\"\"\"\n",
    "    \n",
    "    fdf = FactorizedDataFrame(data, row, col)\n",
    "    \n",
    "    subplots_kw = {\n",
    "        \"gridspec_kw\": {'hspace': 1},\n",
    "        **subplots_kw,\n",
    "        \"squeeze\": False, # axes should always be two-dimensional\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(len(fdf.row_values), len(fdf.col_values), **subplots_kw)\n",
    "\n",
    "    for f in fdf.iter_factorized():\n",
    "        ax = axes[f.ri, f.ci]\n",
    "        ax.set_title(f.title)\n",
    "        legend = f.ri == len(fdf.row_values)-1 and f.ci == len(fdf.col_values)-1\n",
    "        plot(f, ax, legend)\n",
    "        if legend:\n",
    "            plt.legend(loc='lower left', bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Committerslot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "bucketprefix = \"prb_write__committerslothist_b_\"\n",
    "buckets = list(filter(lambda col: col.find(bucketprefix) == 0, tmp.columns))\n",
    "rename = {col: col[len(bucketprefix):] for col in buckets}\n",
    "df_cslot = tmp[buckets].copy()\n",
    "df_cslot = df_cslot.rename(rename, axis=1)\n",
    "df_cslot = df_cslot.rename_axis(columns='bucket')\n",
    "df_cslot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that other is zero\n",
    "assert (df_cslot['other'] == 0).all()\n",
    "# drop it\n",
    "del df_cslot['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = pd.DataFrame(tmp.stack().rename('count').reset_index())\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp.reset_index()\n",
    "tmp['bucket'] = tmp.bucket.astype('int64')\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp.reset_index()\n",
    "tmp['weight'] = tmp.bucket.map(lambda v: v + 1)\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Committer Slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsum = df_cslot['count'].unstack('bucket').sum(axis=1)\n",
    "countsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedcount = (df_cslot['count'] * df_cslot['weight']).unstack('bucket').sum(axis=1)\n",
    "weightedcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_committer_slot = pd.DataFrame((weightedcount / countsum).rename('avg_committer_slot'))\n",
    "avg_committer_slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(avg_committer_slot, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = avg_committer_slot.unstack('ncommitters').plot(figsize=(10,5))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Committer Slot Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cslot['count'].unstack('bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp['count'].unstack('bucket')\n",
    "# delete colums that only contain zeroes\n",
    "# https://stackoverflow.com/questions/21164910/how-do-i-delete-a-column-that-contains-only-zeros-in-pandas\n",
    "tmp = tmp.loc[:, (tmp != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.div(tmp.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = tmp.query(\"numjobs in [1,4,8,12,16,24]\")\n",
    "ncommitters_values = sorted(list(set(tmp.index.get_level_values('ncommitters'))))\n",
    "print(ncommitters_values)\n",
    "numjobs_values = sorted(list(set(tmp.index.get_level_values('numjobs'))))\n",
    "\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "#     display(f.d)\n",
    "    f.d.plot.bar(ax=ax, stacked=True, legend=False)\n",
    "#     f.d.plot.area(ax=ax, legend=False)\n",
    "    \n",
    "    if not f.is_last_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "factorplot(tmp, col='interleaving', row='numjobs', plot=plot,\n",
    "                subplots_kw={\n",
    "                    \"figsize\": (15,  5 + len(numjobs_values)*1.2),\n",
    "            #         \"figsize\": (10, (0.6666) * (5 + 3*1)),\n",
    "                    \"gridspec_kw\": {\n",
    "                        \"hspace\": 1,\n",
    "                    },\n",
    "                })\n",
    "\n",
    "# for i in ncommitters_values:\n",
    "#     tmp.query('ncommitters == @i').plot.area(figsize=(15,1.5), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Time Spent Per IOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_iop_df():\n",
    "    return df.copy()\n",
    "#     return df.copy().query('ncommitters in [1,2,4,8,16,18]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "\n",
    "data = data[[\"cpu_utilization\"]].unstack(\"ncommitters\")\n",
    "ax = data.plot(figsize=(12,5), ylim=(0, 1.1))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  IOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "# data = data.query('numjobs in [1,4,8,16] and ncommitters in [1,2,4,8,16]')\n",
    "\n",
    "data = data[[\"w_iops_mean\"]].unstack(\"ncommitters\")\n",
    "ax = data.plot(figsize=(12,5), ylim=(0,None))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CPU Per IOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "\n",
    "data['cpu_per_iop'] = data.cpu_not_idle / data.w_iops_mean\n",
    "\n",
    "data = data[[\"cpu_per_iop\"]].unstack(\"ncommitters\")\n",
    "ax = data.plot(figsize=(12,5), ylim=(0, None))\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "# data = data.query('numjobs in [1,4,8,16] and ncommitters in [1,2,4,8,16]')\n",
    "data = data.query('ncommitters in [1,2,3,4,8,12,24]')\n",
    "data = data.query('numjobs <= 18')\n",
    "\n",
    "data['cpu_per_iop'] = data.cpu_not_idle / data.w_iops_mean\n",
    "data['pmem_time_per_iop'] = data.prb_write__pmem / data.w_iops_mean\n",
    "\n",
    "\n",
    "data = data[[\n",
    "    \"w_iops_mean\",\n",
    "    \"w_lat_mean\",\n",
    "    \"cpu_per_iop\",\n",
    "#     \"avg_committer_slot\",\n",
    "    \"pmem_time_per_iop\",\n",
    "    \"w_lat_stddev\",\n",
    "]]\n",
    "data = data.rename_axis(\"metric\", axis=1)\n",
    "data = pd.DataFrame(data.stack().rename(\"metric_value\"))\n",
    "data = data.sort_index()\n",
    "# display(data)\n",
    "\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "#     display(f.d)\n",
    "\n",
    "    data = f.d.copy().unstack(\"ncommitters\")\n",
    "    xticks = list(range(0, 19, 2))\n",
    "    if f.rv == \"prb_write__pmem\":\n",
    "         ax = data.plot(ax=ax, ylim=(0, 150_000_000_000), xticks=xticks, legend=False)       \n",
    "    elif f.rv == \"pmem_time_per_iop\":\n",
    "        ylim=(1e5, (1e6))\n",
    "#         ax = data.plot(ax=ax, logy=True, ylim=ylim, yticks=np.arange(ylim[0], ylim[1], (10**6)), xticks=xticks, legend=False)        \n",
    "#         ax = data.plot(ax=ax, logy=True, ylim=ylim, yticks=np.arange(1e5, 1e7, 1e5), xticks=xticks, legend=False)       \n",
    "        ax = data.plot(ax=ax, ylim=(10_000, 600_000), xticks=xticks, logy=False, legend=False)        \n",
    "    elif f.rv == 'avg_committer_slot':\n",
    "        ax = data.plot(ax=ax, ylim=(0,10), yticks=range(0,10), xticks=xticks, legend=False)        \n",
    "    elif f.rv == 'cpu_per_iop':\n",
    "        ax = data.plot(ax=ax, ylim=(0,0.007), xticks=xticks, legend=False)\n",
    "    elif f.rv == 'w_iops_mean':\n",
    "        # data = data[[\"cpu_per_iop\"]].unstack(\"ncommitters\")\n",
    "        ax = data.plot(ax=ax, ylim=(0, 900_000),xticks=xticks,  legend=False)\n",
    "        # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    elif f.rv == 'w_lat_mean':\n",
    "        # data = data[[\"cpu_per_iop\"]].unstack(\"ncommitters\")\n",
    "        ax = data.plot(ax=ax, ylim=(0, 50_000), xticks=xticks, legend=False)\n",
    "#         ax = data.plot(ax=ax, logy=True, ylim=(8000, 200_000), yticks=[1e4, 2e4, 4e4, 8e4, 1e5, 2e5, 4e5, 8e5], xticks=xticks, legend=False)\n",
    "#         ax = data.plot(ax=ax, logy=True, ylim=(8000, 200_000), yticks=[1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4, 8e4, 9e4, 1e5, 2e5, 3e5, 4e5], xticks=xticks, legend=False)\n",
    "        # ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    elif f.rv == 'w_lat_stddev':\n",
    "        ax = data.plot(ax=ax, ylim=(0, 50_000), xticks=xticks,  legend=False)\n",
    "    else:\n",
    "        display(f.d)\n",
    "        raise Exception(\"unknown row\")\n",
    "        \n",
    "    if legend:\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    if not f.is_last_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "factorplot(data, col='interleaving', row='metric', plot=plot,\n",
    "                subplots_kw={\n",
    "                    \"figsize\": (20,  25),\n",
    "            #         \"figsize\": (10, (0.6666) * (5 + 3*1)),\n",
    "                    \"gridspec_kw\": {\n",
    "                        \"hspace\": 0.1,\n",
    "                    },\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
