{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": \"talk\",\n",
    "    \"savefig\": {\n",
    "        \"enable\": True,\n",
    "        \"dir\": Path(\"./postprocess_results\"),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))\n",
    "\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_storage_prefix = \"ncommitters_scalability__v2\"\n",
    "\n",
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "    # regular\n",
    "    # (\"zfs_setup.module_args.zfs.zfs_zil_pmem_prb_ncommitters\", \"ncommitters\", int),\n",
    "    # ncommitters_scalability_v2\n",
    "    (\"file_ctime\", \"file_ctime\", int),\n",
    "    \n",
    "    (\"fio_config.numjobs\", \"numjobs\", int),\n",
    "    \n",
    "    ('pmem_setup_data.interleaving', \"interleaving\", int),\n",
    "    \n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return jw\n",
    "\n",
    "def to_fio_results_dict(output_json):\n",
    "    jw = get_fio_write_metrics(output_json)\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "    }\n",
    "\n",
    "def to_kstat_results_dict(output_json):\n",
    "    d = output_json\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        **d[\"zvol_stats\"],\n",
    "        **d[\"itxg_bypass_stats\"],\n",
    "        **d[\"zil_pmem_stats\"],\n",
    "        **d[\"zil_pmem_ringbuf_stats\"],\n",
    "        \"bio_total\": d[\"zvol_stats\"][\"submit_bio__zvol_write(with_taskq_if_enabled)\"],\n",
    "        \"taskq_delay\": dotted.get(d, 'zvol_stats.zvol_write__taskq_qdelay'),\n",
    "        \"assign_aquire\": dotted.get(d, 'itxg_bypass_stats.assign__aquisition_total'),\n",
    "        \"assign_vtable\": dotted.get(d, 'itxg_bypass_stats.assign__vtable'),\n",
    "        \"assign_total\": dotted.get(d, 'itxg_bypass_stats.assign__total'),\n",
    "        \"commit_total\": dotted.get(d, 'itxg_bypass_stats.commit__total'),\n",
    "        \"commit_aquire\": dotted.get(d, 'itxg_bypass_stats.commit__aquire'),\n",
    "    }\n",
    "\n",
    "def to_cpu_dict(output_json):\n",
    "    d = output_json\n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        **{f\"cpu_{comp}\": val for comp, val in dotted.get(d, \"cpu_time.allcpu\").items()},\n",
    "    }\n",
    "\n",
    "def to_unified_dict(output_json):\n",
    "    d = output_json\n",
    "    \n",
    "    jw = get_fio_write_metrics(output_json)\n",
    "    \n",
    "    return {\n",
    "        **extract_id_var_values(output_json),\n",
    "        \n",
    "        # fio\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "        \n",
    "        # kstats\n",
    "        **d[\"zvol_stats\"],\n",
    "        **d[\"itxg_bypass_stats\"],\n",
    "        **d[\"zil_pmem_stats\"],\n",
    "        **d[\"zil_pmem_ringbuf_stats\"],\n",
    "        \"bio_total\": d[\"zvol_stats\"][\"submit_bio__zvol_write(with_taskq_if_enabled)\"],\n",
    "        \"taskq_delay\": dotted.get(d, 'zvol_stats.zvol_write__taskq_qdelay'),\n",
    "        \"assign_aquire\": dotted.get(d, 'itxg_bypass_stats.assign__aquisition_total'),\n",
    "        \"assign_vtable\": dotted.get(d, 'itxg_bypass_stats.assign__vtable'),\n",
    "        \"assign_total\": dotted.get(d, 'itxg_bypass_stats.assign__total'),\n",
    "        \"commit_total\": dotted.get(d, 'itxg_bypass_stats.commit__total'),\n",
    "        \"commit_aquire\": dotted.get(d, 'itxg_bypass_stats.commit__aquire'),\n",
    "        \n",
    "        # cpu stats\n",
    "        **{f\"cpu_{comp}\": val for comp, val in dotted.get(d, \"cpu_time.allcpu\").items()},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISABLED IN ncommitters_scalability__v2, next cellb elow\n",
    "rows = [{**to_unified_dict(j)} for j in result_storage.iter_results(result_storage_prefix)]\n",
    "df = pd.DataFrame.from_dict(rows)\n",
    "# df = df.set_index(id_vars, verify_integrity=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncommitters_scalability__v2 specific fixups (we forgot to record the storage stack config)\n",
    "ncommitters_sequence = [1,2,3,4,5,6,7,8,9,10,11,12,14,16,18]\n",
    "numjobs_sequence = list(range(1,25))\n",
    "ncommitters_df = []\n",
    "for il in [4, 1]:\n",
    "    for nc in ncommitters_sequence:\n",
    "        for nj in numjobs_sequence:\n",
    "            ncommitters_df += [{\"interleaving\": il, \"numjobs\": nj, \"ncommitters\": nc}]\n",
    "ncommitters_df = pd.DataFrame(ncommitters_df)\n",
    "ncommitters_df['file_ctime'] = df['file_ctime']\n",
    "join_cols = ['interleaving', 'file_ctime', 'numjobs']\n",
    "ncommitters_df = ncommitters_df.set_index(join_cols)\n",
    "tmp = df.set_index(join_cols)\n",
    "merged = ncommitters_df.merge(tmp, left_index=True, right_index=True)\n",
    "id_vars = [\"interleaving\", \"numjobs\", \"ncommitters\"]\n",
    "df = merged.reset_index().drop('file_ctime', axis=1).set_index(id_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post-process cpu utilization\n",
    "tmp = df.filter(regex=\"^cpu_.*\", axis=1)\n",
    "# display(tmp)\n",
    "cpu_total = tmp.sum(axis=1)\n",
    "df['cpu_not_idle'] = cpu_total - df.cpu_idle\n",
    "# second socket was disabled => half of total cpu time is idle time\n",
    "df['cpu_utilization'] = df.cpu_not_idle / (cpu_total - (cpu_total/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Committerslot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kstat = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketprefix = \"prb_write__committerslothist_b_\"\n",
    "buckets = list(filter(lambda col: col.find(bucketprefix) == 0, df_kstat.columns))\n",
    "rename = {col: col[len(bucketprefix):] for col in buckets}\n",
    "df_cslot = df_kstat[buckets].copy()\n",
    "df_cslot = df_cslot.rename(rename, axis=1)\n",
    "df_cslot = df_cslot.rename_axis(columns='bucket')\n",
    "df_cslot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that other is zero\n",
    "assert (df_cslot['other'] == 0).all()\n",
    "# drop it\n",
    "del df_cslot['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = pd.DataFrame(tmp.stack().rename('count').reset_index())\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp.reset_index()\n",
    "tmp['bucket'] = tmp.bucket.astype('int64')\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp.reset_index()\n",
    "tmp['weight'] = tmp.bucket.map(lambda v: v + 1)\n",
    "tmp = tmp.set_index(id_vars + [\"bucket\"])\n",
    "df_cslot = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Committer Slot Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cslot['count'].unstack('bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_cslot.copy()\n",
    "tmp = tmp['count'].unstack('bucket')\n",
    "# delete colums that only contain zeroes\n",
    "# https://stackoverflow.com/questions/21164910/how-do-i-delete-a-column-that-contains-only-zeros-in-pandas\n",
    "tmp = tmp.loc[:, (tmp != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.div(tmp.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncommitters_values = sorted(list(set(tmp.index.get_level_values('ncommitters'))))\n",
    "print(ncommitters_values)\n",
    "for i in ncommitters_values:\n",
    "    tmp.query('ncommitters == @i').plot.area(figsize=(15,1.5), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Committer Slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsum = df_cslot['count'].unstack('bucket').sum(axis=1)\n",
    "countsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedcount = (df_cslot['count'] * df_cslot['weight']).unstack('bucket').sum(axis=1)\n",
    "weightedcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame((weightedcount / countsum).rename('avg_committer_slot')).unstack('ncommitters').plot(figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU Time Per IOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_iop_df():\n",
    "    return df.copy().query('ncommitters in [1,2,4,8,16,18]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "# data = data.query('numjobs in [1,4,8,16] and ncommitters in [1,2,4,8,16]')\n",
    "\n",
    "data = data[[\"w_iops_mean\"]].unstack(\"ncommitters\")\n",
    "data.plot(figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "# data = data.query('numjobs in [1,4,8,16] and ncommitters in [1,2,4,8,16]')\n",
    "\n",
    "data = data[[\"cpu_utilization\"]].unstack(\"ncommitters\")\n",
    "data.plot(figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cpu_iop_df()\n",
    "data = data.reset_index()\n",
    "data = data.query('ncommitters in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]')\n",
    "data = data.set_index(id_vars)\n",
    "\n",
    "data['cpu_per_iop'] = data.cpu_not_idle / data.w_iops_mean\n",
    "\n",
    "data = data[[\"cpu_per_iop\"]].unstack(\"ncommitters\")\n",
    "data.plot(figsize=(15,10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
