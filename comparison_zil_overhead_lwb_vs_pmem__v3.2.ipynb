{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* v3.2:\n",
    "  * prettier graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import dotted # https://pypi.org/project/dotted-notation/\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.datasciencetoolbelt as dstools\n",
    "from lib.resultstorage import ResultStorage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def filter_by_index_value(df, level, filter):\n",
    "    \"\"\"Return a new df that only contains rows whose MultiIndex column `level`'s value passes `filter`\"\"\"\n",
    "    return df[df.index.get_level_values(level).map(filter)]\n",
    "\n",
    "def remove_index_dimension(df, level, value):\n",
    "    \"\"\"Reduce dimensionality of a dataframe by filtering by and subsequently dropping one of its index levels.\n",
    "    \n",
    "    df is assumed to be a multi-indexed pd.DataFrame.\n",
    "    First, filter the data frame so that we only keep rows whose index tuple has value `value` at level `level`.\n",
    "    Now the resulting data frame only has a single value at the level.\n",
    "    Thus remove that level from the index.\n",
    "    Voila: dimensionality reduced.\n",
    "    \"\"\"\n",
    "    df = df[df.index.get_level_values(level) == value]\n",
    "    assert set(df.index.get_level_values(level)) == {value}\n",
    "    df.index = df.index.droplevel(level)\n",
    "    return df\n",
    "\n",
    "def _test_remove_index_dimension():\n",
    "    data = [{\"favnum\": n, \"favletter\": l, \"id\": id} for id, (n, l) in enumerate(itertools.product([23,42],[\"a\", \"b\"]))]\n",
    "    d = pd.DataFrame(data).set_index([\"favnum\", \"favletter\"])\n",
    "    display(d)\n",
    "    display(remove_index_dimension(d, \"favnum\", 23))\n",
    "    display(remove_index_dimension(d, \"favletter\", \"b\"))\n",
    "    \n",
    "_test_remove_index_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_values_sorted_unique(df, level):\n",
    "    \"\"\"Returns the sorted unique values of a DataFrame's multi-index at level `level`\"\"\"\n",
    "    return sorted(list(set(df.index.get_level_values(level))))\n",
    "\n",
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "class FactorizedDataFrameItem(AttrDict):\n",
    "    @property\n",
    "    def title(self):\n",
    "        if self.fdf.row and self.fdf.col:\n",
    "            return f\"{self.fdf.row}={self.rv}|{self.fdf.col}={self.cv}\"\n",
    "        elif self.fdf.row:\n",
    "            return f\"{self.fdf.row}={self.rv}\"\n",
    "        elif self.fdf.col:\n",
    "            return f\"{self.fdf.col}={self.cv}\"\n",
    "        else:\n",
    "            return \"\"\n",
    "            \n",
    "        \n",
    "class FactorizedDataFrame:\n",
    "    def __init__(self, data, row, col):\n",
    "        self.data = data\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "\n",
    "        self.col_values = [None] if not self.col else level_values_sorted_unique(self.data, self.col)\n",
    "        self.row_values = [None] if not self.row else level_values_sorted_unique(self.data, self.row)\n",
    "        \n",
    "    def iter_factorized(self):\n",
    "        for ci, c in enumerate(self.col_values):\n",
    "            for ri, r in enumerate(self.row_values):\n",
    "                d = self.data.copy()\n",
    "                if c:\n",
    "                    d = remove_index_dimension(d, self.col, c)\n",
    "                if r:\n",
    "                    d = remove_index_dimension(d, self.row, r)\n",
    "                # display(d)\n",
    "            \n",
    "                context = FactorizedDataFrameItem({\n",
    "                    \"fdf\": self,\n",
    "                    \"d\": d,\n",
    "                    \"ri\": ri,\n",
    "                    \"rv\": r,\n",
    "                    \"ci\": ci,\n",
    "                    \"cv\": c,\n",
    "                    \"is_last_row\": ri == len(self.row_values)-1,\n",
    "                    \"is_last_col\": ci == len(self.col_values)-1,\n",
    "                })\n",
    "                yield context\n",
    "                \n",
    "\n",
    "def factorplot(data=None, row=None, col=None, plot=None, subplots_kw={}):\n",
    "    \"\"\"Factorizez MultiIndex'ed DataFrame `data`, then invokes `plot` for each FactorizedDataFrameItem\"\"\"\n",
    "    \n",
    "    fdf = FactorizedDataFrame(data, row, col)\n",
    "    \n",
    "    subplots_kw = {\n",
    "        \"gridspec_kw\": {'hspace': 1},\n",
    "        **subplots_kw,\n",
    "        \"squeeze\": False, # axes should always be two-dimensional\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(len(fdf.row_values), len(fdf.col_values), **subplots_kw)\n",
    "\n",
    "    for f in fdf.iter_factorized():\n",
    "        ax = axes[f.ri, f.ci]\n",
    "        ax.set_title(f.title)\n",
    "        legend = f.ri == len(fdf.row_values)-1 and f.ci == len(fdf.col_values)-1\n",
    "        plot(f, ax, legend)\n",
    "        if legend:\n",
    "            plt.legend(loc='lower left', bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "savefig_enable = True\n",
    "seaborn_context = \"paper\"\n",
    "savefig_dir = \"./postprocess_results\"\n",
    "textwidth = 5.5 #inch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstools.setup({\n",
    "    \"seaborn_context\": seaborn_context,\n",
    "    \"savefig\": {\n",
    "        \"enable\": savefig_enable,\n",
    "        \"dir\": Path(savefig_dir),\n",
    "    }\n",
    "})\n",
    "result_storage = ResultStorage(Path(\"./results\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars__dottedpath_and_shortname_and_type = [\n",
    "#     ('result.identity', \"benchmark\", str),  \n",
    "    (\"storage_stack.identity\", \"storage_stack\", str),\n",
    "    (\"result.fio_config.numjobs\", \"numjobs\", int),\n",
    "]\n",
    "id_vars = [p[1] for p in id_vars__dottedpath_and_shortname_and_type]\n",
    "\n",
    "def extract_id_var_values(output_json):\n",
    "    d = output_json\n",
    "    id_var_values = {}\n",
    "    for dp, sn, ty in id_vars__dottedpath_and_shortname_and_type: \n",
    "        v = dotted.get(d, dp)\n",
    "        if not v:\n",
    "            raise Exception(f\"{d['file']}: dotted path {dp} not found\")\n",
    "        if sn in id_var_values:\n",
    "            raise Exception(f\"duplicate shortname {sn}\")\n",
    "        try:\n",
    "            id_var_values[sn] = ty(v)\n",
    "        except ValueError as e:\n",
    "            raise Exception(f\"cannot parse v={v!r}\") from e\n",
    "    return id_var_values\n",
    "\n",
    "\n",
    "def get_fio_write_metrics(output_json):\n",
    "    d = output_json\n",
    "    jobs = dotted.get(d, \"fio_jsonplus.jobs\")\n",
    "    assert len(jobs) == 1\n",
    "    j0 = jobs[0]\n",
    "    jw = jobs[0][\"write\"]\n",
    "    return {\n",
    "        \"w_iops_mean\": jw[\"iops_mean\"],\n",
    "        \"w_iops_stddev\": jw[\"iops_stddev\"],\n",
    "        \"w_lat_mean\": dotted.get(jw, \"lat_ns.mean\"),\n",
    "        \"w_lat_stddev\": dotted.get(jw, \"lat_ns.stddev\"),\n",
    "    }\n",
    "\n",
    "\n",
    "def to_row_dict(output_json):\n",
    "    try:\n",
    "        r = {}\n",
    "        for k, v in dotted.get(output_json, \"result.latency_analysis\").items():\n",
    "            assert k[0] == '@'\n",
    "            k = k[1:] # strip leading @\n",
    "            assert k not in r\n",
    "            r[k] = v\n",
    "\n",
    "        r = {\n",
    "            **extract_id_var_values(output_json),\n",
    "            \"fio_metrics\": get_fio_write_metrics(output_json['result']),\n",
    "            **r,\n",
    "        }\n",
    "        return r\n",
    "    except:\n",
    "        print(json.dumps(output_json))\n",
    "        raise\n",
    "\n",
    "rows = [to_row_dict(j) for j in result_storage.iter_results(\"comparison_zil_overhead_lwb_vs_pmem__v3\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(rows)\n",
    "df = df.set_index(id_vars)\n",
    "df = df.sort_index()\n",
    "display(df)\n",
    "# display(df / 1_000_000)\n",
    "# compute zfs write breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "\n",
    "del tmp['fio_metrics']\n",
    "\n",
    "display(tmp)\n",
    "\n",
    "tmp['async'] = tmp.zfs_write - tmp.zil_commit - tmp.zfs_log_write\n",
    "tmp['zil_persistence'] = tmp.zil_commit - tmp.zil_fill_commit_list\n",
    "\n",
    "components = [\"async\", \"zfs_log_write\", \"zil_fill_commit_list\", \"zil_persistence\"]\n",
    "\n",
    "# cummulative latencies\n",
    "display(tmp[components])\n",
    "# per-write latencies\n",
    "tmp = tmp[components].div(tmp.zfs_write_count, axis=0)\n",
    "display(tmp)\n",
    "df_latbreakdown = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.copy()\n",
    "df_fio = tmp['fio_metrics'].apply(pd.Series)\n",
    "df_fio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Latency Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = df_latbreakdown.copy()\n",
    "total = data.sum(axis=1)\n",
    "# display(data)\n",
    "# display(total)\n",
    "data = data.div(total, axis=0)\n",
    "# display(data)\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "    f.d.plot.bar(ax=ax, ylim=(0, 1.1), legend=legend, stacked=True)\n",
    "    if not f.is_last_row:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    \n",
    "factorplot(data, row='storage_stack', col=None, plot=plot, subplots_kw={\n",
    "    \"figsize\": (10, 10),\n",
    "    \"gridspec_kw\": {'hspace': 0.2},\n",
    "})\n",
    "\n",
    "# data.loc[\"zfs-lwb-rs_0\", ].plot.area(**kwargs)\n",
    "# data.loc[\"zfs-pmem-rs_0-byp_0-nc_3\", ].plot.area(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Absolute Latency Normalized By IOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_latbreakdown\n",
    "\n",
    "def plot(f, ax, legend):\n",
    "    f.d.plot.bar(ax=ax, ylim=(0, None), legend=legend, stacked=False)\n",
    "    if not f.is_last_row:\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_xticklabels([])\n",
    "        \n",
    "    \n",
    "factorplot(data, row='storage_stack', col=None, plot=plot, subplots_kw={\n",
    "    \"figsize\": (10, 10),\n",
    "    \"gridspec_kw\": {'hspace': 0.2},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fio-perceived IOPS and Latency For Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_fio.w_lat_mean.unstack(\"storage_stack\").plot.bar(figsize=(10,5), subplots=True, yticks=range(0, 100_000, 20_000))\n",
    "ax = df_fio.w_lat_mean.unstack(\"storage_stack\").plot(figsize=(10,5))\n",
    "ax.legend(bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ax = df_fio.w_iops_mean.unstack(\"storage_stack\").plot.bar(figsize=(10,5), subplots=True)\n",
    "ax = df_fio.w_iops_mean.unstack(\"storage_stack\").plot(figsize=(10,5))\n",
    "ax.legend(bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All One Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relbreakdown = df_latbreakdown.copy()\n",
    "total = relbreakdown.sum(axis=1)\n",
    "relbreakdown = relbreakdown.div(total, axis=0)\n",
    "# display(relbreakdown)\n",
    "\n",
    "abs_breakdown = df_latbreakdown.copy()\n",
    "\n",
    "measurement_error = df_fio.w_lat_mean - abs_breakdown.copy().sum(axis=1)\n",
    "\n",
    "rows = [\n",
    "    (\"relbreakdown\", \"Relative Latency Breakdown (eBPF)\"),\n",
    "    (\"abs_breakdown\", \"Latency Breakdown Per IOP (eBPF)\"),\n",
    "    (\"fio_latency_and_delta\", \"Latency Measured By Fio & Delta to eBPF\"),\n",
    "#     (\"measurement_error\", \"Latency Per IOPS Delta (fio - eBPF)\"),  # covered in fio_latency_and_delta\n",
    "\n",
    "    #     (\"fio_iops\", \"IOPS (fio)\"),\n",
    "    #     \"abs\", # useless because accumulates measurement overhead\n",
    "    #     (\"iops\"),\n",
    "#     (\"latency_std\"),\n",
    "]\n",
    "nrows = len(rows)\n",
    "ncols = 2\n",
    "g, axes = plt.subplots(nrows, ncols, figsize=(15,5 * nrows), gridspec_kw = {'hspace': 0.4})\n",
    "for row in range(0, nrows):\n",
    "    for col in range(0, ncols):\n",
    "        \n",
    "        storage_stack = {\n",
    "            0: 'zfs-lwb-rs_0',\n",
    "            1: 'zfs-pmem-rs_0-byp_0-nc_3',\n",
    "        }[col]\n",
    "        \n",
    "        \n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        row_name, row_displayname = rows[row]\n",
    "        \n",
    "        try:\n",
    "\n",
    "            if row_name == \"relbreakdown\":\n",
    "                relbreakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 1.1), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"abs_breakdown\":\n",
    "                abs_breakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 95_000), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"abs\":\n",
    "                df_latbreakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 6_000_000_000), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"fio_iops\":\n",
    "                df_fio.loc[storage_stack, \"w_iops_mean\"].plot.bar(ax=ax, ylim=(0, 400_000))\n",
    "            elif row_name == \"fio_latency_and_delta\":\n",
    "                yerr = measurement_error.loc[storage_stack, ]\n",
    "                df_fio.loc[storage_stack, \"w_lat_mean\"].plot.bar(ax=ax, ylim=(0, 95_000), yerr=yerr)\n",
    "            elif row_name == \"latency_std\":\n",
    "                df_fio.loc[storage_stack, \"w_lat_stddev\"].plot(ax=ax)\n",
    "            elif row_name == \"measurement_error\":\n",
    "                measurement_error.loc[storage_stack, ].plot.bar(ax=ax, ylim=(-1_000, 3_000))\n",
    "            else:\n",
    "                raise Exception(f\"unknown row name {row_name}\")\n",
    "            ax.set_title(f\"{row_displayname if row_displayname else row_name}\")\n",
    "        \n",
    "        except:\n",
    "            print(row_name)\n",
    "            raise\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relbreakdown = df_latbreakdown.copy()\n",
    "total = relbreakdown.sum(axis=1)\n",
    "relbreakdown = relbreakdown.div(total, axis=0)\n",
    "# display(relbreakdown)\n",
    "\n",
    "abs_breakdown = df_latbreakdown.copy()\n",
    "\n",
    "measurement_error = df_fio.w_lat_mean - abs_breakdown.copy().sum(axis=1)\n",
    "\n",
    "rows = [\n",
    "    (\"relbreakdown\", \"Relative Latency Breakdown (eBPF)\"),\n",
    "    (\"abs_breakdown\", \"Latency Breakdown Per IOP (eBPF)\"),\n",
    "    (\"fio_latency_and_delta\", \"Latency Measured By Fio & Delta to eBPF\"),\n",
    "    (\"measurement_error\", \"Latency Per IOPS Delta (fio - eBPF)\"), # covered in fio_latency_and_delta\n",
    "    \n",
    "#     (\"fio_iops\", \"IOPS (fio)\"),\n",
    "#     \"abs\", # useless because accumulates measurement overhead\n",
    "    #     (\"iops\"),\n",
    "#     (\"latency_std\"),\n",
    "]\n",
    "nrows = len(rows)\n",
    "ncols = 2\n",
    "g, axes = plt.subplots(nrows, ncols, figsize=(15,5 * nrows), gridspec_kw = {'hspace': 0.4})\n",
    "for row in range(0, nrows):\n",
    "    for col in range(0, ncols):\n",
    "        \n",
    "        storage_stack = {\n",
    "            0: 'zfs-lwb-rs_0',\n",
    "            1: 'zfs-pmem-rs_0-byp_0-nc_3',\n",
    "        }[col]\n",
    "        \n",
    "        \n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        row_name, row_displayname = rows[row]\n",
    "        \n",
    "        try:\n",
    "\n",
    "            if row_name == \"relbreakdown\":\n",
    "                relbreakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 1.1), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"abs_breakdown\":\n",
    "                abs_breakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 85_000), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"abs\":\n",
    "                df_latbreakdown.loc[storage_stack, ].plot.bar(ax=ax, stacked=True, ylim=(0, 6_000_000_000), legend=False)\n",
    "                if col == ncols - 1:\n",
    "                    ax.legend(loc=\"center left\", bbox_to_anchor=(1,0.5))\n",
    "            elif row_name == \"fio_iops\":\n",
    "                df_fio.loc[storage_stack, \"w_iops_mean\"].plot.bar(ax=ax, ylim=(0, 400_000))\n",
    "            elif row_name == \"fio_latency_and_delta\":\n",
    "                yerr = measurement_error.loc[storage_stack, ]\n",
    "                df_fio.loc[storage_stack, \"w_lat_mean\"].plot.bar(ax=ax, ylim=(0, None), yerr=yerr)\n",
    "            elif row_name == \"latency_std\":\n",
    "                df_fio.loc[storage_stack, \"w_lat_stddev\"].plot(ax=ax)\n",
    "            elif row_name == \"measurement_error\":\n",
    "                measurement_error.loc[storage_stack, ].plot.bar(ax=ax, ylim=None)\n",
    "            else:\n",
    "                raise Exception(f\"unknown row name {row_name}\")\n",
    "            ax.set_title(f\"{row_displayname if row_displayname else row_name}\")\n",
    "        \n",
    "        except:\n",
    "            print(row_name)\n",
    "            raise\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(textwidth, 3.5), gridspec_kw={\"hspace\":0.05, \"wspace\":0.05})\n",
    "\n",
    "def drawCol(col, storage_stack, title, ylabel):\n",
    "\n",
    "    ax = axes[0, col]\n",
    "    relbreakdown.mul(100).apply(np.ceil).loc[storage_stack, ].plot.bar(\n",
    "        ax=ax, stacked=True, ylim=(0, 100), legend=False,\n",
    "        ylabel=\"Relative [%]\" if ylabel else \"\",\n",
    "        title=title)    \n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    if not ylabel:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    ax=axes[1, col]\n",
    "    abs_breakdown.div(1_000).loc[storage_stack, ].plot.bar(\n",
    "        ax=ax, stacked=True, legend=False,\n",
    "        ylabel=\"Absolute [us]\" if ylabel else \"\"\n",
    "    )           \n",
    "    ax.set_xlabel(\"numjobs\")\n",
    "    ax.set_ylim(0, 90)\n",
    "    if not ylabel:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "drawCol(0, 'zfs-lwb-rs_0', \"ZIL-LWB\", True)\n",
    "drawCol(1, 'zfs-pmem-rs_0-byp_0-nc_3', \"ZIL-PMEM\", False)   \n",
    "\n",
    "handles, labels = axes[1, 1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='center', title=\"Component\", bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "fig.suptitle(\"Average IOP Latency Breakdown\", fontsize=10, y=1.01)\n",
    "\n",
    "dstools.savefig(\"comparison_zil_overhead_lwb_vs_pmem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
